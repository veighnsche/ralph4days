
 ▐▛███▜▌   Claude Code v2.1.34
▝▜█████▛▘  Opus 4.6 · Claude API
  ▘▘ ▝▝    ~/Projects/ralph4days

❯ /clear 
  ⎿  (no content)

❯ There was an article online WHY some code agent suppliers DON'T add a RAG 
   database for code conceptualizing                                        

● Interesting topic. The argument against RAG for code conceptualization
  typically boils down to a few points:

  1. Context windows are big enough now — Modern models (100K-200K tokens) can
  hold entire codebases or substantial portions, making retrieval less necessary
   for many projects.
  2. Code has structure that RAG handles poorly — Code semantics depend on call
  graphs, type hierarchies, and control flow. Naive chunk-and-embed misses these
   relationships. A function signature means nothing without understanding its
  callers and callees.
  3. Embeddings struggle with code — Natural language embeddings don't capture
  code semantics well. sort_ascending and sort_descending embed as nearly
  identical, but do opposite things. Symbol names are arbitrary and misleading.
  4. Retrieval introduces false confidence — When a RAG system returns
  "relevant" chunks, the model treats them as authoritative context. But if the
  retrieval missed a critical override or edge case elsewhere in the codebase,
  the model confidently generates wrong code.
  5. Grep/glob + model reasoning beats embeddings — Letting the model use
  structured search tools (exact string matching, AST queries, file patterns)
  gives it deterministic, complete results. The model can reason about what to
  search for, which is more reliable than hoping an embedding space captures
  relevance.
  6. Maintenance burden — Keeping a vector DB in sync with a rapidly changing
  codebase (every save, every branch) adds complexity. The index is always
  slightly stale, and stale code context is worse than no context.

  The counterargument is that for very large codebases (millions of lines), you
  need some form of retrieval because you can't fit it all in context. But the
  trend has been toward better tool use (letting the agent search iteratively)
  rather than pre-indexing into vectors.

  Do you have the article link? I'd be curious to read their specific take.

❯ Can you find it please...  

● Web Search("why code agents don't use RAG database for code conceptualizing
            2025 2026")
  ⎿  Did 1 search in 7s

● Web Search("code AI agents no RAG vector database code understanding article")
  ⎿  Did 1 search in 8s

● Web Search(""why we don't use RAG" coding assistant codebase indexing against
            article blog")
  ⎿  Did 1 search in 9s

● Web Search("cursor aider claude code no RAG indexing codebase search tools
            instead")
  ⎿  Did 1 search in 8s

● Found several articles that match what you're describing. The most likely
  ones:

  The Cline article — probably the one you saw:
  - https://cline.bot/blog/why-cline-doesnt-index-your-codebase-and-why-thats-a-
  good-thing

  Other strong matches on the same topic:
  - https://jxnl.co/writing/2025/09/11/why-i-stopped-using-rag-for-coding-agents
  -and-you-should-too/ — Jason Liu (567 Labs)
  - https://pashpashpash.substack.com/p/why-i-no-longer-recommend-rag-for —
  Substack post
  - https://medium.com/@animesh1997/why-rag-falls-short-for-autonomous-coding-ag
  ents-86cf5b3dcb69 — Medium

  Counterpoint (pro-RAG):
  - https://milvus.io/blog/why-im-against-claude-codes-grep-only-retrieval-it-ju
  st-burns-too-many-tokens.md — Milvus blog arguing the grep-only approach burns
   too many tokens

  The Cline one is the most widely shared — does that ring a bell, or was it one
   of the others?

✻ Baked for 31s

❯ It was exactly that... so in our system.. I want to also make use of RAG  
  system... But it's specified for the feature alone... Idk how I'm goign   
  to design this.. but now that you have reasons WHY NOT!!!                 
                                                                            
  What would be the most feasible design to bind a rag system for our       
  features system?                                                          

● This is a great design challenge. The anti-RAG arguments are almost entirely
  about whole-codebase code indexing — but what you're describing is
  fundamentally different. Let me lay out why, and then a feasible design.

  Why Feature-Scoped RAG Sidesteps the Problems
  Anti-RAG Argument: Code chunks lose meaning
  Why it doesn't apply here: You're not chunking code — you're indexing feature 
    artifacts (tasks, decisions, learnings, file maps)
  ────────────────────────────────────────
  Anti-RAG Argument: Index goes stale
  Why it doesn't apply here: Features have finite lifetimes — index is
    rebuilt/updated per iteration
  ────────────────────────────────────────
  Anti-RAG Argument: Embeddings miss code semantics
  Why it doesn't apply here: Your data is structured natural language (task
    descriptions, acceptance criteria), where embeddings
     actually work well
  ────────────────────────────────────────
  Anti-RAG Argument: Whole-codebase security risk
  Why it doesn't apply here: Scoped to one feature's context at a time
  ────────────────────────────────────────
  Anti-RAG Argument: Grep works fine
  Why it doesn't apply here: Grep works for finding code. It doesn't help Haiku
    recall "we tried approach X and it failed because Y"
  The key insight: this isn't code RAG — it's feature memory RAG.

  What Goes In the Index (Per Feature)

  This matters more than the technology choice:

  - Task descriptions + acceptance criteria
  - File registry — which files this feature touches (built up over iterations)
  - Decision log — what was tried, what worked, what didn't
  - Error patterns — errors encountered and their resolutions
  - Inter-task dependency context
  - Code snippets only for interfaces/signatures (not full implementations)

  Recommended Design: SQLite FTS5 via MCP

  Given Ralph's architecture ("thinnest wrapper", dynamic MCP servers):

  .ralph/db/
    tasks.yaml
    features.yaml
    ...
    rag/
      feature_auth.db      ← SQLite FTS5 per feature
      feature_payments.db

  Why SQLite FTS5 over vector embeddings:
  - Zero external dependencies (no embedding model, no vector DB)
  - Already available in Rust (rusqlite)
  - BM25 ranking built-in — great for structured text
  - Tiny, portable, per-feature files
  - Stays true to "thinnest wrapper" — no ML infrastructure

  How it flows:

  1. Iteration starts for feature "auth"
  2. Ralph opens/creates .ralph/db/rag/feature_auth.db
  3. Ralph generates MCP server exposing:
     - search_feature_context(query) → FTS5 search
     - get_feature_decisions() → recent decision log
     - get_feature_files() → file registry
  4. Prompt builder tells Haiku: "Use search_feature_context to recall prior
  work"
  5. Haiku searches instead of getting everything dumped in prompt
  6. After iteration, Ralph indexes:
     - New/changed task content
     - Files touched (from Claude's tool use output)
     - Learnings extracted from iteration output

  The critical part: Step 6 is where Ralph parses Claude's stream-json output
  after each iteration and feeds structured artifacts back into the feature's
  FTS5 index. This is what builds the memory over time.

  What This Buys You

  - Haiku stays cheap — pulls only relevant context instead of getting the full
  PRD every time
  - Cross-iteration memory — "we tried X, it broke because Y" persists without
  bloating prompts
  - Feature isolation — working on "auth" doesn't pollute context with
  "payments" history
  - Opus reviews get richer — can query the feature's full history for deeper
  analysis

  Want me to dig deeper into any part of this, or start planning the
  implementation?

✻ Sautéed for 59s

❯ Can you Please do a deep investigation and really make an implementation  
  plan in the docs                                                          

● Let me do a thorough investigation of the codebase first, then write the plan.

● Explore(Deep codebase investigation for RAG)
  ⎿  Done (65 tool uses · 155.7k tokens · 3m 32s)

● Now let me confirm the doc numbering and read the existing blueprint doc
  before writing.

● Read 1 file (ctrl+o to expand)

● Bash(ls -1 /home/vince/Projects/ralph4days/.docs/ | sort | tail -5)
  ⎿  012_INFERRED_TASK_STATUS_IMPLEMENTATION.md
     013_INFERRED_STATUS_UI_INTEGRATION.md
     014_SIMPLIFIED_INFERRED_STATUS_UI.md
     … +2 lines (ctrl+o to expand)

● Good. I have a thorough picture of the codebase. Doc 015 is the foundation —
  schema exists but is completely unwired. The new doc needs to go beyond 015's
  "fs::read_to_string" vision into actual search-based retrieval with
  accumulated feature memory. Let me write it.

● Write(.docs/017_FEATURE_SCOPED_RAG_SYSTEM.md)
  ⎿  Wrote 487 lines to .docs/017_FEATURE_SCOPED_RAG_SYSTEM.md
      1 # Feature-Scoped RAG System
      2 
      3 **Created:** 2026-02-07
      4 **Status:** Implementation Plan
      5 **Depends on:** Doc 015 (Task Model as Prompt Assembly Nexus)
      6 
      7 ## Context
      8 
      9 Doc 015 established the "Task Model as Prompt Assembly Nexus" — t
        asks reference Disciplines (HOW) and Features (WHAT), and Ralph a
        ssembles surgical prompts from all three. It added `knowledge_pat
        hs` and `context_files` to the Feature schema and described three
         phases:
     … +477 lines (ctrl+o to expand)

● Done. Created .docs/017_FEATURE_SCOPED_RAG_SYSTEM.md.

  Here's what the doc covers:

  Core idea: This is NOT code RAG — it's feature memory RAG. After each
  iteration, Ralph extracts structured data (files touched, decisions, errors,
  summaries) and stores it per-feature in SQLite FTS5. Future iterations search
  this memory via MCP tools instead of getting everything dumped into the
  prompt.

  Key design decisions:
  - SQLite FTS5 over vector embeddings — Ralph is not AI, BM25 ranking is
  deterministic and sufficient
  - MCP for retrieval — Haiku pulls what it needs on-demand, scales with history
  - One .db file per feature — isolation, trivial cleanup, no cross-feature
  leakage
  - Fire-and-forget extraction — memory write failures never break the loop

  Implementation phases:
  - Phase 0 (prerequisite): Wire up Doc 015 foundation — CRUD for
  knowledge_paths/context_files, surgical prompt builder, task selection in loop
   engine
  - Phase 1: Memory store write path — rusqlite + FTS5, extract tool_use events
  from stream-json, write after each iteration
  - Phase 2: Memory retrieval read path — bash MCP server wrapping sqlite3
  queries, --mcp-config in autonomous loop
  - Phase 3: Auto-enrichment — files touched 3+ times auto-populate
  context_files
  - Phase 4: Frontend visibility (optional)

  Critical dependency: Phase 0 (Doc 015's task selection) must come first —
  without it, Ralph doesn't know which feature is being worked on.

✻ Cogitated for 7m 10s

❯ Alright... let's make RAG optional... but if we should add qdrant and     
  ollama required dependencies.. Please look at the kilo code repo to learn 
   about how they do RAG with qdrant and ollama... I don't want to support  
  other db or embedding provider for now                                    

● Web Search("Kilo Code RAG qdrant ollama implementation github")
  ⎿  Did 1 search in 7s

● Web Search("kilo code repository qdrant ollama embedding codebase indexing")
  ⎿  Did 1 search in 7s

● Web Search("site:github.com Kilo-Org/kilocode codebase indexing qdrant source
            code")
  ⎿  Error: Sibling tool call errored

● Fetch(https://kilo.ai/docs/features/codebase-indexing)
  ⎿  Error: Sibling tool call errored

● Fetch(https://kilo.ai/docs/advanced-usage/available-tools/codebase-search)
  ⎿  Error: Request failed with status code 404

● Fetch(https://kilo.ai/docs/customize/context/codebase-indexing)
  ⎿  Received 70.7KB (200 OK)

● Web Search("Kilo-Org kilocode github codebase indexing source code qdrant
            embedding TypeScript")
  ⎿  Did 1 search in 7s

● Fetch(https://github.com/Kilo-Org/kilocode)
  ⎿  Received 390.3KB (200 OK)

● Fetch(https://raw.githubusercontent.com/Kilo-Org/kilocode/main/src/services/co
       de-indexing/index.ts)
  ⎿  Error: Request failed with status code 404

● Fetch(https://raw.githubusercontent.com/Kilo-Org/kilocode/main/packages/code-i
       ndexing/src/index.ts)
  ⎿  Error: Sibling tool call errored

● Task(Find Kilo Code RAG source code) Sonnet 4.5
  ⎿  Done (50 tool uses · 63.3k tokens · 5m 31s)

● Got a thorough picture of Kilo Code's implementation. Let me now update the
  doc to use Qdrant + Ollama instead of SQLite FTS5, with the RAG system as
  optional.

● Read 1 file (ctrl+o to expand)

● Now I'll rewrite the doc with Qdrant + Ollama as the technology choice, RAG as
   optional, and patterns learned from Kilo Code.

● Write(.docs/017_FEATURE_SCOPED_RAG_SYSTEM.md)
  ⎿  Added 430 lines, removed 186 lines
      3  **Created:** 2026-02-07
      4  **Status:** Implementation Plan
      5  **Depends on:** Doc 015 (Task Model as Prompt Assembly Nexus)
      6 +**Reference:** [Kilo Code codebase indexing](https://github.com/
        +Kilo-Org/kilocode) — Qdrant + Ollama patterns adapted for featur
        +e-scoped use                                                    
      7  
      8  ## Context
      9  
     ...
      13  - Phase 2 (Assemble): Prompt builder — **not started**
      14  - Phase 3 (Refine): MCP resources — **not started**
      15  
      15 -This document extends Doc 015 with a **feature memory** layer: 
         -after each iteration, Ralph extracts what happened and stores i
         -t per-feature. Future iterations can *search* this memory for r
         -elevant context rather than getting everything dumped into the 
         -prompt.                                                        
      16 +This document extends Doc 015 with a **feature memory** layer: 
         +after each iteration, Ralph extracts what happened, embeds it v
         +ia Ollama, and stores vectors in Qdrant per-feature. Future ite
         +rations can *semantically search* this memory for relevant cont
         +ext rather than getting everything dumped into the prompt.     
      17  
      18 +**RAG is optional.** The system degrades gracefully when Qdrant
         + or Ollama are unavailable — Doc 015's static file injection st
         +ill works. RAG enriches the experience but is never required.  
      19 +                                                               
      20  ## Motivation: Why Feature-Scoped RAG
      21  
      22  The [Cline blog post](https://cline.bot/blog/why-cline-doesnt-i
          ndex-your-codebase-and-why-thats-a-good-thing) and similar arti
          cles argue against RAG for code agents. Their arguments are val
          id for **whole-codebase code indexing**. Feature-scoped RAG sid
          esteps every one:
     ...
      25  |---|---|---|
      26  | Code chunks lose meaning when split | Chunking arbitrary code
           destroys logic flow | We're indexing **feature artifacts** — t
          asks, decisions, learnings, file maps — not code chunks |
      27  | Index goes stale instantly | Codebase changes every save/comm
          it | Features have **finite lifetimes**; memory is rebuilt/upda
          ted per iteration |
      25 -| Embeddings miss code semantics | `sort_asc` and `sort_desc` e
         -mbed identically | Our data is natural language (task descripti
         -ons, error messages, decision rationale) — embeddings/FTS work 
         -well |                                                         
      26 -| Whole-codebase is a security risk | Entire IP in a vector DB 
         -| Scoped to one feature's context, stored locally in `.ralph/db
         -/` |                                                           
      27 -| Grep + reasoning beats embeddings for code | True for finding
         - code definitions/usage | Grep can't answer "what did we try la
         -st time and why did it fail?" — that requires memory |         
      28 +| Embeddings miss code semantics | `sort_asc` and `sort_desc` e
         +mbed identically | Our data is natural language (task descripti
         +ons, error messages, decision rationale) — embeddings work well
         + here |                                                        
      29 +| Whole-codebase is a security risk | Entire IP in a vector DB 
         +| Scoped to one feature's context, local Qdrant instance |     
      30 +| Grep + reasoning beats embeddings for code | True for finding
         + code definitions/usage | Grep can't answer "what did we try la
         +st time and why did it fail?" — that requires semantic memory |
      31  
      32  **The key insight:** this is not code RAG. It is **feature memo
          ry RAG** — structured natural-language artifacts accumulated ov
          er iterations.
      33  
     ...
      42  
      43  Feature memory gives Haiku **cross-iteration continuity** withi
          n a feature, without bloating the prompt with full history.
      44  
      45 +## Required Dependencies (Optional — RAG disabled when absent) 
      46 +                                                               
      47 +### Qdrant (Vector Database)                                   
      48 +                                                               
      49 +Local Docker instance. Single command setup:                   
      50 +                                                               
      51 +```bash                                                        
      52 +docker run -d --name qdrant -p 6333:6333 -p 6334:6334 \        
      53 +  -v ~/.ralph/qdrant_storage:/qdrant/storage \                 
      54 +  qdrant/qdrant                                                
      55 +```                                                            
      56 +                                                               
      57 +- REST API at `http://localhost:6333`                          
      58 +- gRPC at `localhost:6334` (used by Rust client for performance
         +)                                                              
      59 +- Storage persisted to `~/.ralph/qdrant_storage` (survives cont
         +ainer restarts)                                                
      60 +- No authentication needed for local use                       
      61 +                                                               
      62 +### Ollama (Embedding Model)                                   
      63 +                                                               
      64 +Local Ollama instance with an embedding model:                 
      65 +                                                               
      66 +```bash                                                        
      67 +# Install ollama (if not already)                              
      68 +curl -fsSL https://ollama.com/install.sh | sh                  
      69 +                                                               
      70 +# Pull embedding model                                         
      71 +ollama pull nomic-embed-text                                   
      72 +```                                                            
      73 +                                                               
      74 +- API at `http://localhost:11434`                              
      75 +- Default model: `nomic-embed-text` (768 dimensions, good for n
         +atural language)                                               
      76 +- Alternative: `mxbai-embed-large` (1024 dimensions, higher qua
         +lity)                                                          
      77 +                                                               
      78 +### Why Only Qdrant + Ollama                                   
      79 +                                                               
      80 +No other providers supported. Rationale:                       
      81 +- **Local-only**: All data stays on-machine. No API keys, no cl
         +oud, no cost-per-embed.                                        
      82 +- **One path**: Ralph's "Single Execution Path Policy" — no pro
         +vider abstraction layer, no feature flags, no alternate backend
         +s.                                                             
      83 +- **Dev environment match**: Target machine has RTX 3090 — Olla
         +ma with GPU acceleration is fast.                              
      84 +- **Kilo Code validated this stack**: Qdrant + Ollama is a prov
         +en combination for local code tooling.                         
      85 +                                                               
      86  ## What Goes Into Feature Memory
      87  
      88  ### Structured Records (per iteration)
     ...
      90  Each completed iteration produces a `FeatureMemoryEntry`:
      91  
      92  ```yaml
      49 -# Conceptual schema — actual storage is SQLite                 
      93 +# Conceptual schema — actual storage is Qdrant vectors         
      94  - iteration: 7
      95    task_id: 42
      96    task_title: "Build login form component"
     ...
      113    tokens_used: 45000
      114  ```
      115  
       72 -### What Gets Indexed for Search                              
      116 +### What Gets Embedded and Stored                             
      117  
       74 -Two categories of content go into the FTS5 index:             
      118 +Each entry becomes **one Qdrant point** with:                 
      119  
       76 -1. **Iteration summaries** — Natural language descriptions of 
          -what happened, extracted from Claude's output. Searchable for 
          -"what was tried" and "what went wrong."                       
      120 +- **Vector**: Ollama embedding of a combined text: `"{task_tit
          +le}\n{summary}\n{errors}\n{decisions}"`                       
      121 +- **Payload** (stored alongside vector, returned with search r
          +esults):                                                      
      122 +  - `iteration_number: u32`                                   
      123 +  - `task_id: u32`                                            
      124 +  - `task_title: String`                                      
      125 +  - `discipline: String`                                      
      126 +  - `feature: String`                                         
      127 +  - `timestamp: String`                                       
      128 +  - `outcome: String` (success/failure/partial)               
      129 +  - `summary: String`                                         
      130 +  - `errors: Vec<String>`                                     
      131 +  - `decisions: Vec<String>`                                  
      132 +  - `files_touched: Vec<{path, action}>`                      
      133 +  - `tokens_used: Option<u32>`                                
      134  
       78 -2. **File registry** — Which files were touched by which tasks
          -. Searchable for "what files matter for this feature" — this i
          -s how `context_files` grows automatically.                    
       79 -                                                              
      135  ### What Does NOT Go Into Feature Memory
      136  
      137  - Raw code content (that's what `context_files` + `fs::read_to
           _string` is for)
      138  - Full Claude output transcripts (too large, mostly noise)
       84 -- Other features' data (strict feature isolation)             
      139 +- Other features' data (strict feature isolation via Qdrant co
          +llection-per-feature)                                         
      140  
      141  ## How Memory Accumulates
      142  
     ...
      148  Claude finishes iteration
      149          │
      150          ▼
       96 -┌─────────────────────┐                                       
       97 -│  Parse stream-json   │  ← Already happening (claude_client.r
          -s)                                                            
       98 -│  output for:         │                                      
       99 -│  - assistant text    │  ← Currently captured                
      100 -│  - tool_use events   │  ← NEW: capture file read/write/edit 
          -tool calls                                                    
      101 -│  - result event      │  ← Currently ignored, has cost_usd + 
          -summary                                                       
      102 -└─────────┬───────────┘                                       
      151 +┌─────────────────────────┐                                   
      152 +│  Parse stream-json       │  ← Already happening (claude_clie
          +nt.rs)                                                        
      153 +│  output for:             │                                  
      154 +│  - assistant text        │  ← Currently captured            
      155 +│  - tool_use events       │  ← NEW: capture file read/write/e
          +dit tool calls                                                
      156 +│  - result event          │  ← Currently ignored, has cost_us
          +d + summary                                                   
      157 +└─────────┬───────────────┘                                   
      158            │
      159            ▼
      105 -┌─────────────────────┐                                       
      106 -│  Extract structured  │  ← NEW: post-iteration extraction    
      107 -│  data:               │                                      
      108 -│  - files touched     │  (from tool_use: Read, Write, Edit to
          -ol names + paths)                                             
      109 -│  - summary           │  (from result event or last assistant
          - text)                                                        
      110 -│  - outcome           │  (task status change in YAML = succes
          -s, no change = failure)                                       
      111 -│  - errors            │  (regex patterns in assistant text: "
          -error", "failed", "TypeError")                                
      112 -└─────────┬───────────┘                                       
      160 +┌─────────────────────────┐                                   
      161 +│  Extract structured      │  ← NEW: post-iteration extraction
      162 +│  data:                   │                                  
      163 +│  - files touched         │  (from tool_use: Read, Write, Edi
          +t tool names + paths)                                         
      164 +│  - summary               │  (from result event or last assis
          +tant text)                                                    
      165 +│  - outcome               │  (task status change in YAML = su
          +ccess, no change = failure)                                   
      166 +│  - errors                │  (regex patterns in assistant tex
          +t: "error", "failed", "TypeError")                            
      167 +└─────────┬───────────────┘                                   
      168            │
      169            ▼
      115 -┌─────────────────────┐                                       
      116 -│  Determine feature   │  ← From task that was worked on (pars
          -e YAML diff or                                                
      117 -│                      │     from prompt builder's target task
          -)                                                             
      118 -└─────────┬───────────┘                                       
      170 +┌─────────────────────────┐                                   
      171 +│  Determine feature       │  ← From task that was worked on (
          +parse YAML diff or                                            
      172 +│                          │     from prompt builder's target 
          +task)                                                         
      173 +└─────────┬───────────────┘                                   
      174            │
      175            ▼
      121 -┌─────────────────────┐                                       
      122 -│  Write to feature's  │  ← .ralph/db/memory/<feature_name>.db
      123 -│  SQLite FTS5 index   │                                      
      124 -└─────────────────────┘                                       
      176 +┌─────────────────────────┐                                   
      177 +│  Check RAG availability  │  ← Is Qdrant reachable? Is Ollama
          + running?                                                     
      178 +│  (skip if unavailable)   │                                  
      179 +└─────────┬───────────────┘                                   
      180 +          │ (available)                                       
      181 +          ▼                                                   
      182 +┌─────────────────────────┐                                   
      183 +│  Embed via Ollama        │  ← POST http://localhost:11434/ap
          +i/embed                                                       
      184 +│  "{title}\n{summary}     │     model: nomic-embed-text      
      185 +│   \n{errors}\n{decisions}"│     → 768-dim vector            
      186 +└─────────┬───────────────┘                                   
      187 +          │                                                   
      188 +          ▼                                                   
      189 +┌─────────────────────────┐                                   
      190 +│  Upsert to Qdrant        │  ← Collection: feature-<sha256(fe
          +ature_name)[:16]>                                             
      191 +│  point: {vector, payload} │     Adapted from Kilo Code's ws-
          +<hash> pattern                                                
      192 +└─────────────────────────┘                                   
      193  ```
      194  
      195  ### Extracting Files Touched from stream-json
     ...
      237  
      238  ### Query Interface via MCP
      239  
      172 -Ralph generates an MCP server per feature that exposes search:
      240 +Ralph generates an MCP server that exposes semantic search ove
          +r feature memory:                                             
      241  
      242  ```
      243  MCP Tools:
      176 -  search_feature_memory(query: string, limit?: number) → Memor
          -yEntry[]                                                      
      244 +  search_feature_memory(query: string, limit?: number, min_sco
          +re?: number) → MemoryEntry[]                                  
      245    get_recent_iterations(count?: number) → MemoryEntry[]
      178 -  get_feature_files() → FileEntry[]      # all files ever touc
          -hed for this feature                                          
      246 +  get_feature_files() → FileEntry[]       # all files ever tou
          +ched for this feature                                         
      247    get_failed_attempts(task_id?: number) → MemoryEntry[]
      248  ```
      249  
      182 -The MCP server is a bash script (consistent with existing `mcp
          -_generator.rs` pattern) that shells out to `sqlite3` for queri
          -es. The `sqlite3` CLI is available on virtually all Linux syst
          -ems.                                                          
      250 +The MCP server is a small Rust sidecar binary (not a bash scri
          +pt — Qdrant queries are too complex for shell). It:           
      251 +- Connects to Qdrant REST API at `http://localhost:6333`      
      252 +- Calls Ollama to embed the search query                      
      253 +- Queries the feature's collection with cosine similarity     
      254 +- Returns results as JSON-RPC 2.0 responses over stdio        
      255  
      256  ### Query Flow in an Iteration
      257  
      258  ```
      259  1. Loop engine selects task T in feature F
      188 -2. Prompt builder constructs base prompt (Doc 015 assembly)   
      189 -3. MCP generator creates feature-memory MCP server for F      
      190 -4. Claude CLI launched with --mcp-config including feature-mem
          -ory server                                                    
      191 -5. Prompt includes instruction: "Use search_feature_memory to 
          -check for prior work on this task"                            
      192 -6. Haiku queries memory as needed during execution            
      193 -7. After iteration: extract → index (as described above)      
      260 +2. Check RAG availability (Qdrant + Ollama health check)      
      261 +3. If RAG available:                                          
      262 +   a. Prompt builder constructs base prompt (Doc 015 assembly)
      263 +   b. MCP generator creates feature-memory MCP sidecar for F  
      264 +   c. Claude CLI launched with --mcp-config including feature-
          +memory server                                                 
      265 +   d. Prompt includes: "Use search_feature_memory to check for
          + prior work"                                                  
      266 +4. If RAG unavailable:                                        
      267 +   a. Prompt builder constructs base prompt (Doc 015 assembly)
          + — no memory tools                                            
      268 +   b. Log warning: "RAG unavailable — Qdrant/Ollama not reacha
          +ble"                                                          
      269 +5. Haiku runs iteration                                       
      270 +6. After iteration: extract → embed → store (if RAG available,
          + skip if not)                                                 
      271  ```
      272  
      273  ### Why MCP Over Prompt Injection
     ...
      278  - **Token efficiency**: Haiku only retrieves what it needs, no
           t the full history
      279  - **Haiku decides relevance**: The model is better at formulat
           ing search queries than Ralph is at pre-selecting context
      280  - **Scales with history**: A feature with 50 iterations doesn'
           t mean 50x prompt size
      281 +- **Semantic understanding**: "login form broken" finds entrie
          +s about "authentication form errors" — keyword search can't do
          + this                                                         
      282  - **Consistent pattern**: Already using MCP for ralph-db acces
           s in PTY sessions
      283  
      284  ### Bootstrapping: First Iteration Has No Memory
      285  
      208 -On the first iteration for a feature, the memory DB is empty. 
          -This is fine — the system degrades to Doc 015 behavior (static
          - file injection from `knowledge_paths` + `context_files`). Mem
          -ory enriches the experience over time but is never required.  
      286 +On the first iteration for a feature, the Qdrant collection is
          + empty. This is fine — the system degrades to Doc 015 behavior
          + (static file injection from `knowledge_paths` + `context_file
          +s`). Memory enriches the experience over time but is never req
          +uired.                                                        
      287  
      210 -## Technology Choice: SQLite FTS5                             
      288 +## Technology Choice: Qdrant + Ollama                         
      289  
      212 -### Why SQLite FTS5                                           
      290 +### Why Qdrant                                                
      291  
      214 -| Factor | SQLite FTS5 | Vector DB (e.g., embedded FAISS) | YA
          -ML + grep |                                                   
      215 -|---|---|---|---|                                             
      216 -| Dependencies | `rusqlite` (bundled SQLite) | Python deps or 
          -C++ bindings | None |                                         
      217 -| Search quality | BM25 ranking, phrase/prefix/boolean queries
          - | Semantic similarity | Exact/regex only |                   
      218 -| Fits "thinnest wrapper" | Yes — SQLite is a file, not a serv
          -ice | No — needs embedding model | Yes |                      
      219 -| Unstructured text search | Excellent | Excellent | Poor |   
      220 -| Structured queries | Full SQL | Limited | Manual parsing |  
      221 -| File per feature | Yes (one .db file) | Possible but awkward
          - | Yes (one .yaml) |                                          
      222 -| Human-inspectable | `sqlite3` CLI | No | Yes |              
      223 -| Rust ecosystem | Mature (`rusqlite` crate) | Immature | Nati
          -ve |                                                          
      292 +Adapted from [Kilo Code's implementation](https://github.com/K
          +ilo-Org/kilocode) patterns:                                   
      293  
      225 -**Decision: SQLite FTS5.** It gives real search without introd
          -ucing ML infrastructure. The `rusqlite` crate with `bundled` f
          -eature compiles SQLite from source — zero system dependencies,
          - works everywhere.                                            
      294 +| Factor | Decision |                                         
      295 +|---|---|                                                     
      296 +| **Collection naming** | `feature-<sha256(feature_name)[:16]>
          +` per feature (Kilo uses `ws-<hash>` per workspace) |         
      297 +| **Distance metric** | Cosine (same as Kilo Code) |          
      298 +| **HNSW config** | `m: 64, ef_construct: 512, on_disk: true` 
          +(same as Kilo Code — optimized for quality) |                 
      299 +| **Search params** | `hnsw_ef: 128, exact: false` for fast ap
          +proximate search |                                            
      300 +| **Min score threshold** | `0.4` default (Kilo Code's default
          + — filters irrelevant noise) |                                
      301 +| **Max results** | `20` default (feature memory is smaller th
          +an whole-codebase, need fewer results) |                      
      302 +| **Payload fields** | All structured data stored as payload —
          + returned with search results, no second lookup needed |      
      303 +| **Metadata tracking** | Special metadata point tracks indexi
          +ng state (Kilo Code pattern) |                                
      304  
      227 -### Why Not Vector Embeddings                                 
      305 +**Rust crate**: `qdrant-client` (official Qdrant Rust SDK, use
          +s gRPC for performance)                                       
      306  
      229 -Ralph is NOT AI. Embedding models are AI. Introducing an embed
          -ding model to help the orchestrator contradicts the core philo
          -sophy. FTS5's BM25 ranking is deterministic, fast, and suffici
          -ent for searching natural-language iteration summaries.       
      307 +### Why Ollama                                                
      308  
      231 -### Schema                                                    
      309 +| Factor | Decision |                                         
      310 +|---|---|                                                     
      311 +| **Endpoint** | `http://localhost:11434/api/embed` |         
      312 +| **Default model** | `nomic-embed-text` (768 dims, fast, good
          + for natural language) |                                      
      313 +| **Timeout** | 60s for embeddings, 30s for validation (Kilo C
          +ode's values) |                                               
      314 +| **Batch size** | 1 per iteration (we embed one combined text
          + per iteration, not batches of code chunks) |                 
      315 +| **Validation** | On startup: check Ollama reachable → check 
          +model exists → test embedding capability |                    
      316 +| **Query prefix** | `nomic-embed-text` uses `search_query: ` 
          +prefix for queries, `search_document: ` for documents (Kilo Co
          +de handles this per-model) |                                  
      317  
      233 -```sql                                                        
      234 --- One database per feature: .ralph/db/memory/<feature_name>.d
          -b                                                             
      318 +### Qdrant Collection Schema                                  
      319  
      236 -CREATE TABLE iterations (                                     
      237 -    id INTEGER PRIMARY KEY,                                   
      238 -    iteration_number INTEGER NOT NULL,                        
      239 -    task_id INTEGER NOT NULL,                                 
      240 -    task_title TEXT NOT NULL,                                 
      241 -    discipline TEXT NOT NULL,                                 
      242 -    timestamp TEXT NOT NULL,                                  
      243 -    outcome TEXT NOT NULL CHECK(outcome IN ('success', 'failur
          -e', 'partial')),                                              
      244 -    summary TEXT,                                             
      245 -    errors TEXT,           -- JSON array of error strings     
      246 -    decisions TEXT,         -- JSON array of decision strings 
      247 -    tokens_used INTEGER                                       
      248 -);                                                            
      320 +```                                                           
      321 +Collection: feature-<hash>                                    
      322 +  Vector: 768 dimensions (nomic-embed-text), Cosine distance  
      323  
      250 -CREATE TABLE files_touched (                                  
      251 -    id INTEGER PRIMARY KEY,                                   
      252 -    iteration_id INTEGER NOT NULL REFERENCES iterations(id),  
      253 -    file_path TEXT NOT NULL,                                  
      254 -    action TEXT NOT NULL CHECK(action IN ('created', 'modified
          -', 'read'))                                                   
      255 -);                                                            
      324 +  Point payload schema:                                       
      325 +  {                                                           
      326 +    iteration_number: integer,                                
      327 +    task_id: integer,                                         
      328 +    task_title: keyword,                                      
      329 +    discipline: keyword,                                      
      330 +    feature: keyword,                                         
      331 +    timestamp: keyword,                                       
      332 +    outcome: keyword,         // "success" | "failure" | "part
          +ial"                                                          
      333 +    summary: text,                                            
      334 +    errors: text,             // JSON-serialized Vec<String>  
      335 +    decisions: text,          // JSON-serialized Vec<String>  
      336 +    files_touched: text,      // JSON-serialized Vec<{path, ac
          +tion}>                                                        
      337 +    tokens_used: integer,                                     
      338 +    type: keyword             // "iteration" or "metadata" (fo
          +r tracking)                                                   
      339 +  }                                                           
      340  
      257 --- FTS5 virtual table for full-text search over summaries + er
          -rors + decisions                                              
      258 -CREATE VIRTUAL TABLE memory_fts USING fts5(                   
      259 -    summary,                                                  
      260 -    errors,                                                   
      261 -    decisions,                                                
      262 -    task_title,                                               
      263 -    content=iterations,                                       
      264 -    content_rowid=id                                          
      265 -);                                                            
      341 +  Payload indexes (for filtered queries):                     
      342 +    - task_id: integer index (for get_failed_attempts)        
      343 +    - outcome: keyword index (for filtering by success/failure
          +)                                                             
      344 +    - type: keyword index (to exclude metadata points from sea
          +rch)                                                          
      345 +```                                                           
      346  
      267 --- Triggers to keep FTS in sync                               
      268 -CREATE TRIGGER iterations_ai AFTER INSERT ON iterations BEGIN 
      269 -    INSERT INTO memory_fts(rowid, summary, errors, decisions, 
          -task_title)                                                   
      270 -    VALUES (new.id, new.summary, new.errors, new.decisions, ne
          -w.task_title);                                                
      271 -END;                                                          
      347 +## RAG Availability Detection                                 
      348  
      273 --- Index for file lookups                                     
      274 -CREATE INDEX idx_files_path ON files_touched(file_path);      
      275 -CREATE INDEX idx_files_iteration ON files_touched(iteration_id
          -);                                                            
      276 -CREATE INDEX idx_iterations_task ON iterations(task_id);      
      349 +### Startup Health Check                                      
      350 +                                                              
      351 +On Ralph startup (or when loop starts), check both services:  
      352 +                                                              
      353 +```rust                                                       
      354 +pub struct RagStatus {                                        
      355 +    pub available: bool,                                      
      356 +    pub qdrant_ok: bool,                                      
      357 +    pub ollama_ok: bool,                                      
      358 +    pub ollama_model: Option<String>,    // e.g., "nomic-embed
          +-text"                                                        
      359 +    pub embedding_dims: Option<u32>,     // e.g., 768         
      360 +    pub error: Option<String>,           // Human-readable rea
          +son if unavailable                                            
      361 +}                                                             
      362 +                                                              
      363 +impl RagHealthCheck {                                         
      364 +    /// Check Qdrant: GET http://localhost:6333/healthz       
      365 +    async fn check_qdrant(&self) -> bool;                     
      366 +                                                              
      367 +    /// Check Ollama: GET http://localhost:11434/api/tags     
      368 +    /// Then verify embedding model exists and is embedding-ca
          +pable                                                         
      369 +    /// (POST /api/embed with test input, check response has e
          +mbeddings)                                                    
      370 +    async fn check_ollama(&self) -> (bool, Option<String>, Opt
          +ion<u32>);                                                    
      371 +}                                                             
      372  ```
      373  
      374 +### Behavior When Unavailable                                 
      375 +                                                              
      376 +| Scenario | Behavior |                                       
      377 +|---|---|                                                     
      378 +| Both Qdrant + Ollama running | Full RAG: embed, store, searc
          +h via MCP |                                                   
      379 +| Qdrant down, Ollama up | RAG disabled. Log warning. Loop run
          +s without memory. |                                           
      380 +| Qdrant up, Ollama down | RAG disabled. Log warning. Loop run
          +s without memory. |                                           
      381 +| Both down | RAG disabled. No warning beyond initial log. Nor
          +mal operation. |                                              
      382 +| Ollama model not found | RAG disabled. Log: "nomic-embed-tex
          +t not found. Run: ollama pull nomic-embed-text" |             
      383 +| Qdrant collection missing | Auto-create on first write. Not 
          +an error. |                                                   
      384 +                                                              
      385 +**RAG status is checked once at loop start**, not per-iteratio
          +n. If services go down mid-loop, writes fail silently (fire-an
          +d-forget). MCP server will return empty results if Qdrant is u
          +nreachable.                                                   
      386 +                                                              
      387 +### Frontend Indicator                                        
      388 +                                                              
      389 +Small status badge in the loop control area:                  
      390 +- Green dot: "RAG active" — both services healthy             
      391 +- Gray dot: "RAG off" — services not detected                 
      392 +- Tooltip shows details: "Qdrant: ok | Ollama: nomic-embed-tex
          +t (768d)"                                                     
      393 +                                                              
      394  ## Architecture: Where It Fits
      395  
      396  ```
      282 -                     ┌────────────────────────────────────────
          -─────┐                                                        
      283 -                     │               Loop Engine              
          -      │                                                       
      284 -                     │                                        
          -      │                                                       
      285 -                     │  1. Select task → know feature         
          -      │                                                       
      286 -                     │  2. Prompt builder assembles context   
          -       │                                                      
      287 -                     │  3. MCP generator creates feature-memor
          -y MCP  │                                                      
      288 -                     │  4. Claude client runs iteration       
          -       │                                                      
      289 -                     │  5. MemoryExtractor parses output ◄── N
          -EW    │                                                       
      290 -                     │  6. MemoryStore writes to SQLite  ◄── N
          -EW    │                                                       
      291 -                     │  7. Stagnation check (existing)        
          -      │                                                       
      292 -                     └────────────────────────────────────────
          -─────┘                                                        
      397 +                     ┌────────────────────────────────────────
          +─────────┐                                                    
      398 +                     │               Loop Engine              
          +          │                                                   
      399 +                     │                                        
          +          │                                                   
      400 +                     │  0. Check RAG availability (once at loo
          +p start)  │                                                   
      401 +                     │  1. Select task → know feature         
          +          │                                                   
      402 +                     │  2. Prompt builder assembles context   
          +           │                                                  
      403 +                     │  3. If RAG: MCP generator creates memor
          +y sidecar  │                                                  
      404 +                     │  4. Claude client runs iteration (±MCP)
          +           │                                                  
      405 +                     │  5. MemoryExtractor parses output  ◄── 
          +NEW       │                                                   
      406 +                     │  6. If RAG: embed + upsert Qdrant  ◄── 
          +NEW       │                                                   
      407 +                     │  7. Stagnation check (existing)        
          +          │                                                   
      408 +                     └────────────────────────────────────────
          +─────────┘                                                    
      409                                            │
      410                      ┌─────────────────────┼───────────────────
           ───┐
      411                      │                     │                   
              │
      296 -              .ralph/db/            .ralph/db/memory/      /tm
          -p/ralph-mcp/                                                  
      297 -           tasks.yaml               auth.db              featu
          -re-memory.sh                                                  
      298 -           features.yaml            payments.db          mcp-c
          -onfig.json                                                    
      299 -           disciplines.yaml         ...                       
      300 -           metadata.yaml                                      
      412 +              .ralph/db/           Qdrant (Docker)         /tm
          +p/ralph-mcp/                                                  
      413 +           tasks.yaml            localhost:6333           feat
          +ure-memory sidecar                                            
      414 +           features.yaml         Collections:             mcp-
          +config.json                                                   
      415 +           disciplines.yaml        feature-<hash1>            
      416 +           metadata.yaml           feature-<hash2>            
      417 +                                   ...                        
      418 +                                                     Ollama (l
          +ocalhost:11434)                                               
      419 +                                                       nomic-e
          +mbed-text                                                     
      420  ```
      421  
      422  ### New Modules
     ...
      424  ```
      425  src-tauri/src/
      426    memory/
      308 -    mod.rs            # pub mod extractor; pub mod store; pub 
          -mod mcp;                                                      
      309 -    extractor.rs      # MemoryExtractor — parses claude stream
          --json output into MemoryEntry                                 
      310 -    store.rs          # MemoryStore — SQLite FTS5 read/write o
          -perations                                                     
      311 -    mcp.rs            # Generate feature-memory MCP server bas
          -h script                                                      
      427 +    mod.rs            # pub mod extractor; pub mod store; pub 
          +mod health; pub mod mcp;                                      
      428 +    extractor.rs      # MemoryExtractor — parses stream-json o
          +utput into MemoryEntry                                        
      429 +    store.rs          # MemoryStore — Qdrant + Ollama operatio
          +ns (embed, upsert, search)                                    
      430 +    health.rs         # RagHealthCheck — startup validation of
          + Qdrant + Ollama                                              
      431 +    mcp.rs            # Generate feature-memory MCP sidecar bi
          +nary config                                                   
      432  ```
      433  
      434 +### New Binary: Feature Memory MCP Sidecar                    
      435 +                                                              
      436 +```                                                           
      437 +src-tauri/src/bin/                                            
      438 +  ralph-feature-memory-mcp.rs    # Standalone MCP server binar
          +y                                                             
      439 +```                                                           
      440 +                                                              
      441 +This is a small Rust binary that:                             
      442 +- Reads feature name + Qdrant URL + Ollama URL from CLI args  
      443 +- Implements JSON-RPC 2.0 over stdio (MCP protocol)           
      444 +- On `search_feature_memory`: calls Ollama to embed query → se
          +arches Qdrant → returns results                               
      445 +- On `get_recent_iterations`: scrolls Qdrant collection sorted
          + by timestamp                                                 
      446 +- On `get_feature_files`: aggregates `files_touched` from all 
          +points                                                        
      447 +- On `get_failed_attempts`: filtered search where `outcome = "
          +failure"`                                                     
      448 +                                                              
      449 +Ralph generates an MCP config pointing to this binary:        
      450 +                                                              
      451 +```json                                                       
      452 +{                                                             
      453 +  "mcpServers": {                                             
      454 +    "feature-memory": {                                       
      455 +      "command": "/path/to/ralph-feature-memory-mcp",         
      456 +      "args": ["--feature", "authentication", "--qdrant", "htt
          +p://localhost:6333", "--ollama", "http://localhost:11434"]    
      457 +    }                                                         
      458 +  }                                                           
      459 +}                                                             
      460 +```                                                           
      461 +                                                              
      462  ### Changes to Existing Modules
      463  
      464  | File | Change |
      465  |---|---|
      466  | `claude_client.rs` | Extend `ClaudeOutput` enum with `ToolUs
           e { name, input }` variant. Parse `tool_use` content blocks fr
           om assistant events. Capture `result` event summary. |
      319 -| `loop_engine.rs` | After iteration: call `MemoryExtractor::e
          -xtract()` on collected output, then `MemoryStore::write()`. Pa
          -ss feature name from task selection. |                        
      320 -| `prompt_builder.rs` | Implement `build_task_execution_prompt
          -()` (Doc 015 Phase 2). Add instruction telling Claude about `s
          -earch_feature_memory` tool. |                                 
      321 -| `mcp_generator.rs` | Add `generate_feature_memory_server()` 
          -method. Include in MCP config alongside existing ralph-db serv
          -er. |                                                         
      322 -| `Cargo.toml` | Add `rusqlite = { version = "0.32", features 
          -= ["bundled", "fts5"] }` |                                    
      467 +| `loop_engine.rs` | On loop start: run `RagHealthCheck`. Afte
          +r iteration: call `MemoryExtractor::extract()`, then `MemorySt
          +ore::write()` (if RAG available). Pass feature name from task 
          +selection. |                                                  
      468 +| `prompt_builder.rs` | Implement `build_task_execution_prompt
          +()` (Doc 015 Phase 2). If RAG available: add instruction about
          + `search_feature_memory` tool. |                              
      469 +| `mcp_generator.rs` | Add `generate_feature_memory_mcp()` met
          +hod. Include in MCP config alongside ralph-db server + discipl
          +ine MCP servers. |                                            
      470 +| `commands.rs` | Add `get_rag_status` IPC command for fronten
          +d badge. |                                                    
      471 +| `Cargo.toml` | Add `qdrant-client`, `reqwest` (for Ollama HT
          +TP). |                                                        
      472  
      473 +### Cargo Dependencies                                        
      474 +                                                              
      475 +```toml                                                       
      476 +# src-tauri/Cargo.toml                                        
      477 +[dependencies]                                                
      478 +qdrant-client = "1.13"     # Official Qdrant Rust client (gRPC
          +)                                                             
      479 +# reqwest already used? If not:                               
      480 +reqwest = { version = "0.12", features = ["json"] }  # For Oll
          +ama HTTP API                                                  
      481 +                                                              
      482 +# For the MCP sidecar binary                                  
      483 +[[bin]]                                                       
      484 +name = "ralph-feature-memory-mcp"                             
      485 +path = "src/bin/ralph-feature-memory-mcp.rs"                  
      486 +```                                                           
      487 +                                                              
      488  ## Implementation Phases
      489  
      490  ### Phase 0: Wire Up Doc 015 Foundation (prerequisite)
     ...
      505  - Instead of "pick ONE task" in prompt, Ralph selects the task
            (via `get_ready_tasks()` from Doc 011)
      506  - Enables Ralph to know which feature is being worked on *befo
           re* the iteration
      507  
      344 -### Phase 1: Memory Store (write path)                        
      508 +### Phase 1: RAG Infrastructure                               
      509  
      346 -1a. **Add `rusqlite` dependency** with `bundled` + `fts5` feat
          -ures                                                          
      510 +1a. **Add `qdrant-client` and `reqwest` dependencies**        
      511  
      348 -1b. **Implement `MemoryStore`**                               
      349 -- `new(feature_name, db_dir)` — opens/creates `.ralph/db/memor
          -y/<feature>.db`                                               
      350 -- `initialize()` — creates tables if not exist                
      351 -- `write_entry(entry: MemoryEntry)` — inserts iteration + file
          -s_touched + FTS                                               
      352 -- `search(query, limit)` — FTS5 search with BM25 ranking      
      353 -- `get_recent(count)` — last N iterations                     
      354 -- `get_files()` — distinct files touched, with action counts  
      355 -- `get_failed_for_task(task_id)` — failed iterations for a spe
          -cific task                                                    
      512 +1b. **Implement `RagHealthCheck`**                            
      513 +- `check_qdrant()` — GET `http://localhost:6333/healthz`      
      514 +- `check_ollama()` — GET `http://localhost:11434/api/tags`, ve
          +rify `nomic-embed-text` exists, test embed capability         
      515 +- Returns `RagStatus` struct                                  
      516 +- Called once at loop start, result cached for loop lifetime  
      517  
      357 -1c. **Implement `MemoryExtractor`**                           
      518 +1c. **Implement `MemoryStore`**                               
      519 +- `new(feature_name, qdrant_url, ollama_url)` — creates client
          + connections                                                  
      520 +- `ensure_collection()` — creates Qdrant collection if not exi
          +sts (768 dims, Cosine, HNSW m:64 ef:512)                      
      521 +- `embed_text(text)` — POST to Ollama `/api/embed`, returns `V
          +ec<f32>`                                                      
      522 +- `write_entry(entry: MemoryEntry)` — embeds combined text, up
          +serts point to Qdrant                                         
      523 +- `search(query, limit, min_score)` — embeds query (with `sear
          +ch_query:` prefix), queries Qdrant                            
      524 +- `get_recent(count)` — scroll collection ordered by timestamp
      525 +- `get_files()` — aggregate `files_touched` across all points 
      526 +- `get_failed_for_task(task_id)` — filtered search where `outc
          +ome = "failure"` and `task_id` matches                        
      527 +- `delete_collection()` — cleanup when feature is deleted     
      528 +                                                              
      529 +1d. **Implement `MemoryExtractor`** (same as before — technolo
          +gy-agnostic)                                                  
      530  - Takes collected `Vec<ClaudeOutput>` from an iteration
      359 -- Extracts: files touched, summary, errors, outcome           
      531 +- Extracts: files touched, summary, errors, decisions, outcome
      532  - Returns `MemoryEntry` struct
      533  
      362 -1d. **Extend `claude_client.rs`**                             
      534 +1e. **Extend `claude_client.rs`**                             
      535  - Parse `tool_use` content blocks from assistant events (extra
           ct tool name + input)
      536  - Capture `result` event (currently ignored) for iteration sum
           mary
      537  - Add `ClaudeOutput::ToolUse { name: String, input: serde_json
           ::Value }` variant
      538  - Add `ClaudeOutput::Result { summary: String, cost_usd: Optio
           n<f64> }` variant
      539  
      368 -1e. **Integrate into loop engine**                            
      369 -- After each iteration: extract memory entry, determine featur
          -e, write to store                                             
      370 -- On failure to extract/write: log warning, don't break the lo
          -op                                                            
      540 +1f. **Integrate into loop engine**                            
      541 +- On loop start: run health check, store `RagStatus`          
      542 +- After each iteration: extract memory entry, if RAG available
          +: embed + store                                               
      543 +- On failure to embed/store: log warning, don't break the loop
      544  
      372 -### Phase 2: Memory Retrieval (read path via MCP)             
      545 +### Phase 2: Memory Retrieval (MCP sidecar)                   
      546  
      374 -2a. **Implement feature-memory MCP server generator**         
      375 -- Bash script that wraps `sqlite3` CLI queries                
      376 -- Tools: `search_feature_memory`, `get_recent_iterations`, `ge
          -t_feature_files`, `get_failed_attempts`                       
      377 -- JSON-RPC 2.0 over stdio (same pattern as existing MCP genera
          -tor)                                                          
      547 +2a. **Build `ralph-feature-memory-mcp` binary**               
      548 +- Standalone Rust binary implementing MCP protocol (JSON-RPC 2
          +.0 over stdio)                                                
      549 +- Takes CLI args: `--feature`, `--qdrant`, `--ollama`, `--mode
          +l`                                                            
      550 +- Implements tools: `search_feature_memory`, `get_recent_itera
          +tions`, `get_feature_files`, `get_failed_attempts`            
      551 +- Reuses `MemoryStore` from Phase 1 for actual Qdrant/Ollama c
          +alls                                                          
      552  
      553  2b. **Integrate MCP into autonomous loop**
      554  - `claude_client.rs` adds `--mcp-config` to CLI invocation (cu
           rrently missing)
      381 -- Config includes: ralph-db MCP + feature-memory MCP + discipl
          -ine MCP servers                                               
      555 +- Config includes: ralph-db MCP + feature-memory MCP sidecar +
          + discipline MCP servers                                       
      556  - Loop engine passes MCP config path to claude client
      557 +- Only includes feature-memory MCP if RAG is available        
      558  
      559  2c. **Prompt instructions for memory usage**
      385 -- Add to task execution prompt: "You have access to `search_fe
          -ature_memory` — use it to check for prior work, failed approac
          -hes, and relevant files before starting."                     
      560 +- Add to task execution prompt (when RAG available): "You have
          + access to `search_feature_memory` — use it to check for prior
          + work, failed approaches, and relevant files before starting."
      561  - Add to Opus review prompt: "Use `get_recent_iterations` to r
           eview feature progress across iterations."
      562  
      563 +2d. **Add `get_rag_status` IPC command** for frontend status b
          +adge                                                          
      564 +                                                              
      565  ### Phase 3: Auto-enrichment
      566  
      567  3a. **Auto-populate `context_files` on Feature**
      391 -- After N iterations, aggregate `files_touched` from memory st
          -ore                                                           
      568 +- After N iterations, query Qdrant for all `files_touched` in 
          +feature collection                                            
      569  - Files touched 3+ times across iterations → auto-add to featu
           re's `context_files`
      570  - This makes the static file injection (Doc 015) smarter over 
           time
      571  
     ...
      575  
      576  ### Phase 4: Frontend Visibility (optional, later)
      577  
      401 -4a. **Feature detail view** shows memory stats (iteration coun
          -t, success rate, files touched)                               
      402 -4b. **Timeline view** of feature iterations with outcome badge
          -s                                                             
      403 -4c. **Search UI** — query feature memory from the desktop app 
      578 +4a. **RAG status badge** in loop controls (green/gray dot)    
      579 +4b. **Feature detail view** shows memory stats (iteration coun
          +t, success rate, files touched)                               
      580 +4c. **Timeline view** of feature iterations with outcome badge
          +s                                                             
      581 +4d. **Search UI** — query feature memory from the desktop app 
          +(calls `MemoryStore::search` directly via IPC)                
      582  
      405 -## File/Directory Structure                                   
      583 +## Qdrant Data Lifecycle                                      
      584  
      585 +### Collection Per Feature                                    
      586 +                                                              
      587 +Each feature gets its own Qdrant collection. This provides:   
      588 +- **Isolation**: Searching "auth" never returns "payments" res
          +ults                                                          
      589 +- **Easy deletion**: Drop collection when feature is deleted  
      590 +- **Independent scaling**: Active features accumulate, finishe
          +d features can be pruned                                      
      591 +                                                              
      592 +### Collection Naming                                         
      593 +                                                              
      594  ```
      408 -.ralph/db/                                                    
      409 -  tasks.yaml                                                  
      410 -  features.yaml                                               
      411 -  disciplines.yaml                                            
      412 -  metadata.yaml                                               
      413 -  memory/                    ← NEW directory                  
      414 -    authentication.db        ← SQLite FTS5 per feature        
      415 -    payments.db                                               
      416 -    onboarding.db                                             
      595 +feature-<sha256(feature_name)[:16]>                           
      596  ```
      597  
      419 -The `memory/` directory is:                                   
      420 -- Created on first iteration for a feature (lazy initializatio
          -n)                                                            
      421 -- Gitignored (derived data, not source of truth — can be rebui
          -lt from progress.txt)                                         
      422 -- Backed up/restored with the rest of `.ralph/db/` if needed  
      423 -- Cleaned up when a feature is deleted                        
      598 +Example: feature named `authentication` → collection `feature-
          +a1b2c3d4e5f6a7b8`                                             
      599  
      600 +Adapted from Kilo Code's `ws-<hash>` workspace pattern. Hash p
          +revents collection name issues with special characters.       
      601 +                                                              
      602 +### Point IDs                                                 
      603 +                                                              
      604 +UUID v5 from: `sha256("{feature_name}-{iteration_number}-{task
          +_id}")` — deterministic, idempotent upserts.                  
      605 +                                                              
      606 +### Pruning Strategy                                          
      607 +                                                              
      608 +Not needed initially — feature memory is small (one point per 
          +iteration, ~1KB payload each). A feature with 100 iterations =
          + ~100 points. Qdrant handles millions.                        
      609 +                                                              
      610 +If needed later: prune points where `outcome = "success"` and 
          +`age > 30 days` — keep failures and decisions longer as they'r
          +e more valuable for avoiding repeated mistakes.               
      611 +                                                              
      612 +## Comparison: Before vs After                                
      613 +                                                              
      614 +| Aspect | Without RAG (Doc 015 only) | With RAG (this doc) | 
      615 +|---|---|---|                                                 
      616 +| Cross-iteration memory | None — each iteration amnesiac | Se
          +mantic search over all prior iterations |                     
      617 +| "What was tried before?" | Haiku doesn't know | `search_feat
          +ure_memory("login form validation")` |                        
      618 +| "Why did it fail?" | Rediscovers same errors | Errors from p
          +rior iterations surfaced |                                    
      619 +| File discovery | Manual `context_files` only | Auto-enriched
          + from `files_touched` history |                               
      620 +| Prompt size scaling | Grows with feature complexity | Consta
          +nt — Haiku pulls on demand via MCP |                          
      621 +| Required infrastructure | None | Qdrant (Docker) + Ollama — 
          +**optional** |                                                
      622 +| Degradation | N/A — this IS the baseline | Falls back to Doc
          + 015 behavior seamlessly |                                    
      623 +                                                              
      624  ## Risks and Mitigations
      625  
      626  | Risk | Mitigation |
      627  |---|---|
      429 -| `rusqlite` adds compile time | `bundled` feature avoids syst
          -em SQLite dependency issues. One-time cost. |                 
      430 -| `sqlite3` CLI not on system (for MCP bash script) | Fallback
          -: generate MCP server as a small Rust binary instead of bash. 
          -Or: use `rusqlite` from a Tauri sidecar. |                    
      431 -| Memory extraction is noisy/inaccurate | Start conservative —
          - only extract file paths from tool_use (high confidence). Summ
          -aries from result events. Skip error extraction initially. |  
      432 -| Feature memory grows large | SQLite handles this well. Add `
          -LIMIT` to all queries. Optionally: prune entries older than N 
          -iterations. |                                                 
      433 -| Loop engine complexity increases | Memory extraction is fire
          --and-forget — wrapped in catch-all error handling. Loop never 
          -blocks on memory operations. |                                
      434 -| MCP bash scripts brittle for complex queries | Keep queries 
          -simple. FTS5 `MATCH` syntax is straightforward. Test with fixt
          -ures. |                                                       
      628 +| Qdrant Docker not running | RAG disabled gracefully. Log onc
          +e, run without. |                                             
      629 +| Ollama model not pulled | Health check provides actionable e
          +rror: "Run: ollama pull nomic-embed-text" |                   
      630 +| Ollama embedding latency | One embed per iteration (~100ms o
          +n GPU). Not on hot path. Fire-and-forget. |                   
      631 +| Qdrant storage grows | Local Docker volume. Feature collecti
          +ons are tiny. Pruning strategy if needed. |                   
      632 +| MCP sidecar binary distribution | Built as part of `cargo bu
          +ild`. Tauri bundles it as a sidecar. |                        
      633 +| gRPC dependency from qdrant-client | Pulls in tonic + prost.
          + Compile time increase ~30s. One-time cost. |                 
      634 +| Memory extraction is noisy/inaccurate | Start conservative —
          + only extract file paths from tool_use (high confidence). Summ
          +aries from result events. |                                   
      635 +| Loop engine complexity | RAG is behind availability check. A
          +ll memory ops are fire-and-forget. Loop never blocks on RAG. |
      636  
      637  ## Resolved Design Decisions
      638  
      438 -1. **SQLite over YAML** — YAML is human-readable but can't do 
          -ranked full-text search. Memory is derived data, not human-aut
          -hored. SQLite is the right tool.                              
      639 +1. **Qdrant + Ollama only** — No provider abstraction. No Open
          +AI, no Gemini, no LanceDB. One path. Matches Ralph's Single Ex
          +ecution Path Policy.                                          
      640  
      440 -2. **FTS5 over vector embeddings** — Ralph is not AI. BM25 is 
          -deterministic and sufficient for natural-language iteration su
          -mmaries. No embedding model needed.                           
      641 +2. **RAG is optional** — System works identically without Qdra
          +nt/Ollama. RAG enriches but never gates functionality. Health 
          +check once at loop start, not per-iteration.                  
      642  
      442 -3. **MCP over prompt injection for retrieval** — Per Doc 015 R
          -esolved Question #5. Haiku pulls what it needs on demand. Scal
          -es with history size.                                         
      643 +3. **MCP sidecar over bash script** — Qdrant queries need HTTP
          + client + JSON parsing. Too complex for bash. Small Rust binar
          +y reuses `MemoryStore` code.                                  
      644  
      444 -4. **One DB per feature** — Isolation. Deletion is trivial. No
          - cross-feature query needed. Small files.                     
      645 +4. **One collection per feature** — Isolation, easy cleanup, n
          +o cross-feature leakage. Adapted from Kilo Code's one-collecti
          +on-per-workspace pattern.                                     
      646  
      446 -5. **Memory is optional/supplementary** — System works without
          - memory (degrades to Doc 015 static injection). Memory enriche
          -s but is never required.                                      
      647 +5. **Embed combined text, not individual fields** — One embedd
          +ing per iteration entry (title + summary + errors + decisions 
          +concatenated). Simpler than multi-vector approaches, sufficien
          +t for our use case.                                           
      648  
      448 -6. **Fire-and-forget extraction** — Memory write failures don'
          -t break the loop. Log and continue.                           
      649 +6. **nomic-embed-text as default** — 768 dimensions, fast, goo
          +d for natural language. Kilo Code supports it. Uses query/docu
          +ment prefixes for better retrieval.                           
      650  
      450 -7. **`sqlite3` CLI for MCP** — Consistent with bash-script MCP
          - pattern. Avoids building a separate binary. Fallback plan exi
          -sts if CLI unavailable.                                       
      651 +7. **Fire-and-forget writes** — Memory store failures never br
          +eak the loop. Log warning, continue.                          
      652  
      653 +8. **Cosine similarity with 0.4 threshold** — Kilo Code's defa
          +ult. Filters out irrelevant noise while keeping semantic match
          +es.                                                           
      654 +                                                              
      655  ## Dependency on Doc 015 Phases
      656  
      657  This plan cannot be implemented in isolation. The dependency c
           hain:
     ...
      663      │        │
      664      │        └──→ Doc 015 Phase 0c (task selection in loop)
      665      │                 │
      463 -    │                 ├──→ Phase 1 (memory store — write path)
      666 +    │                 ├──→ Phase 1 (RAG infrastructure — Qdran
          +t/Ollama/extractor)                                           
      667      │                 │        │
      465 -    │                 │        └──→ Phase 2 (memory retrieval 
          -— MCP read path)                                              
      668 +    │                 │        └──→ Phase 2 (MCP sidecar + ret
          +rieval)                                                       
      669      │                 │                 │
      670      │                 │                 └──→ Phase 3 (auto-enr
           ichment)
      671      │                 │
     ...
      676  
      677  **Phase 0 is the critical path.** Without task selection in th
           e loop engine, Ralph doesn't know which feature is being worke
           d on, and memory can't be scoped.
      678  
      679 +## Setup Instructions (for users)                             
      680 +                                                              
      681 +### Quick Start                                               
      682 +                                                              
      683 +```bash                                                       
      684 +# 1. Start Qdrant (one-time)                                  
      685 +docker run -d --name qdrant -p 6333:6333 -p 6334:6334 \       
      686 +  -v ~/.ralph/qdrant_storage:/qdrant/storage \                
      687 +  qdrant/qdrant                                               
      688 +                                                              
      689 +# 2. Install Ollama + embedding model (one-time)              
      690 +curl -fsSL https://ollama.com/install.sh | sh                 
      691 +ollama pull nomic-embed-text                                  
      692 +                                                              
      693 +# 3. Start Ralph — RAG auto-detected                          
      694 +ralph --project /path/to/project                              
      695 +# Console: "RAG: active (Qdrant ok, Ollama nomic-embed-text 76
          +8d)"                                                          
      696 +```                                                           
      697 +                                                              
      698 +### Verify                                                    
      699 +                                                              
      700 +```bash                                                       
      701 +# Check Qdrant                                                
      702 +curl http://localhost:6333/healthz                            
      703 +# → "ok"                                                      
      704 +                                                              
      705 +# Check Ollama                                                
      706 +curl http://localhost:11434/api/tags                          
      707 +# → {"models": [{"name": "nomic-embed-text:latest", ...}]}    
      708 +                                                              
      709 +# Test embedding                                              
      710 +curl http://localhost:11434/api/embed -d '{"model": "nomic-emb
          +ed-text", "input": ["test"]}'                                 
      711 +# → {"embeddings": [[0.123, -0.456, ...]]}                    
      712 +```                                                           
      713 +                                                              
      714 +### Without RAG (default if not set up)                       
      715 +                                                              
      716 +Just run Ralph normally. No Docker, no Ollama needed. Loop wor
          +ks exactly as before. RAG badge shows gray "RAG off".         
      717 +                                                              
      718  ## Open Questions (for future resolution)
      719  
      478 -1. **Should memory survive across `ralph` sessions?** Currentl
          -y yes (persisted in `.ralph/db/memory/`). Could add a "clear m
          -emory" command if needed.                                     
      720 +1. **Should Opus reviews query memory differently than Haiku i
          +terations?** Probably — Opus might want `get_recent_iterations
          +(20)` for a broad view, while Haiku wants `search_feature_memo
          +ry("login form validation")` for specific context.            
      721  
      480 -2. **Should Opus reviews query memory differently than Haiku i
          -terations?** Probably — Opus might want `get_recent_iterations
          -(20)` for a broad view, while Haiku wants `search_feature_memo
          -ry("login form validation")` for specific context.            
      722 +2. **Should memory include cost tracking?** The `result` event
          + includes `cost_usd`. Could aggregate per-feature cost in Qdra
          +nt payload. Useful but not core.                              
      723  
      482 -3. **Should memory include cost tracking?** The `result` event
          - includes `cost_usd`. Could aggregate per-feature cost. Useful
          - but not core to the RAG use case.                            
      724 +3. **Glob patterns in `context_files`?** Doc 015 parked this. 
          +Feature memory's auto-enrichment (Phase 3a) might make this un
          +necessary.                                                    
      725  
      484 -4. **Glob patterns in `context_files`?** Doc 015 parked this. 
          -Feature memory's auto-enrichment (Phase 3a) might make this un
          -necessary — if files are discovered through iterations, explic
          -it globs become redundant.                                    
      726 +4. **Memory portability?** Qdrant data is in Docker volume. No
          +t portable by default. Could add export/import via Qdrant snap
          +shots if needed.                                              
      727  
      486 -5. **Memory portability?** If a project is shared between mach
          -ines, should `.ralph/db/memory/` be synced? Probably not — it'
          -s derived data. But could add an export/import mechanism later
          -.                                                             
      728 +5. **Multiple embedding models?** Currently hardcoded to `nomi
          +c-embed-text`. Could make configurable later. But "one path" p
          +olicy says: not now.                                          
      729 +                                                              
      730 +6. **Ollama GPU vs CPU?** On target machine (RTX 3090), Ollama
          + auto-detects GPU. On machines without GPU, embedding is slowe
          +r but still <1s per iteration entry. Acceptable for fire-and-f
          +orget.                                                        

● Done. The doc has been fully rewritten at
  .docs/017_FEATURE_SCOPED_RAG_SYSTEM.md.

  Here's a summary of the major changes from the SQLite FTS5 version:

  Technology swap:
  - SQLite FTS5 → Qdrant (vector DB, Docker, gRPC via qdrant-client crate) +
  Ollama (nomic-embed-text, 768 dims, local HTTP API)
  - Keyword search (BM25) → semantic similarity (cosine, 0.4 threshold)
  - No other providers. Qdrant + Ollama only. Single execution path.

  Key patterns borrowed from Kilo Code:
  - Collection naming: feature-<sha256[:16]> (adapted from ws-<hash>)
  - HNSW config: m:64, ef_construct:512, on_disk:true
  - Search params: hnsw_ef:128, min_score:0.4
  - Ollama validation: check tags → verify model exists → test embed capability
  - Query prefixes: search_query: / search_document: for nomic-embed-text

  RAG is fully optional:
  - Health check once at loop start (RagStatus struct)
  - Both services must be up; if either is down → RAG disabled, log once, loop
  runs normally
  - Frontend gets a green/gray dot badge via get_rag_status IPC command
  - All memory writes are fire-and-forget — never block the loop

  MCP sidecar instead of bash script:
  - Qdrant queries need HTTP + JSON — too complex for bash
  - Small standalone Rust binary (ralph-feature-memory-mcp) reuses MemoryStore
  code
  - Launched per-iteration with --feature, --qdrant, --ollama args

✻ Baked for 10m 42s

❯ And what about the content? what about the data? can we first look at all 
   our entities... and are we optimized for RAG data usage? I want to start 
   designing the features-feature ... And we still have the capabilities to 
   shape everything around it to make our features extremely helpful for    
  prompt building or mcp accessibility (token effectiveness)                

● Great call — designing the data model for RAG before building the pipeline.
  Let me pull up every entity schema as it exists right now.

● Explore(Read all entity schemas deeply)
  ⎿  Done (24 tool uses · 81.4k tokens · 2m 42s)

● Thorough inventory complete. Here's what stands out — the entities are not 
  optimized for RAG, prompt building, or MCP. Let me lay out the gaps.

  Current State: Entity Audit

  Feature — the thinnest entity, supposed to be the richest

  Feature today:
    name              ✓ identity
    display_name      ✓ display
    acronym           ✓ display
    description       ~ barely used (optional, short)
    created           ✓ timestamp
    knowledge_paths   ✗ EXISTS but unwired (no CRUD, no UI, no prompt use)
    context_files     ✗ EXISTS but unwired (no CRUD, no UI, no prompt use)

  That's it. The entity that's supposed to answer "WHAT domain am I in?" has 7 
  fields, 2 of which are dead. It's a display label, not a knowledge base.

  Discipline — execution context exists but is locked behind YAML-only editing

  Discipline execution fields (all unwired):
    system_prompt     ✗ no CRUD via IPC, no UI
    skills            ✗ no CRUD via IPC, no UI
    conventions       ✗ no CRUD via IPC, no UI
    mcp_servers       ✗ no CRUD via IPC, no UI

  Task — rich schema but the app can't change critical fields

  Task fields with NO IPC write path:
    status            ✗ preserved on update, only agents change it via YAML
    blocked_by        ✗ preserved on update, only agents change it
    completed         ✗ never set by any Rust code at all

  Prompt builder — zero surgical capability

  Everything goes into every prompt. The build_haiku_prompt() concatenates all 4
   raw YAML files + progress.txt + learnings.txt + CLAUDE.md. No field
  selection, no feature scoping, no discipline assembly.

  The Core Problem

  For RAG to be useful, the source data needs to be worth embedding. Right now:

  - Feature.description is typically one sentence — not enough to embed
  meaningfully
  - Feature has no domain knowledge — knowledge_paths/context_files are empty
  - No iteration history on any entity — nowhere to accumulate "what happened"
  - No semantic content worth searching — Feature is a label, not a knowledge
  store

  You can't RAG over empty data.

  Before building the pipeline (Qdrant, Ollama, MCP sidecar), the Feature entity
   needs to become the rich knowledge container that Doc 015 envisioned.

● User answered Claude's questions:
  ⎿  · How do you want to approach the Feature redesign? We can shape the 
     entity model first (what fields Feature should have for 
     RAG/prompt/MCP), or we can start from the user experience (what does a 
     human filling out a Feature form need to provide)? → Data Model first -
      remember that it's mostly AI agents writing all thise.. human RARELY 
     fill things in


     · Should Feature hold its own accumulated knowledge (iteration history,
      decisions, errors), or should that stay separate in Qdrant as planned 
     in doc 017? → This question might be too human-centric


● Perfect framing. Agents write this, not humans. That changes everything — the
  Feature entity needs to be agent-writable and agent-consumable, not a form for
   humans to fill out. Let me design the data model.

● Write(.docs/018_FEATURE_ENTITY_REDESIGN_FOR_RAG.md)
  ⎿  Wrote 624 lines to .docs/018_FEATURE_ENTITY_REDESIGN_FOR_RAG.md
      1 # Feature Entity Redesign for RAG
      2 
      3 **Created:** 2026-02-07
      4 **Status:** Design Proposal
      5 **Depends on:** Doc 015 (Task Model as Prompt Assembly Nexus), Do
        c 017 (Feature-Scoped RAG)
      6 
      7 ## The Problem
      8 
      9 Feature is the thinnest entity in Ralph. It has 7 fields, 2 are d
        ead (knowledge_paths, context_files — exist but no CRUD). It's a 
        display label, not a knowledge base.
     … +614 lines (ctrl+o to expand)

● Created .docs/018_FEATURE_ENTITY_REDESIGN_FOR_RAG.md.

  Here's the core insight from the audit:

  Feature today: 7 fields, basically a display label.
  Feature redesigned: 12 fields, a rich knowledge container.

  New fields:
  Field: architecture
  Who Writes: Braindump/review agent
  Why It Matters: How the feature's pieces connect — prevents contradictory
    decisions across iterations
  ────────────────────────────────────────
  Field: boundaries
  Who Writes: Agent/human
  Why It Matters: IN/OUT OF SCOPE — stops Haiku from scope-creeping into other
    features
  ────────────────────────────────────────
  Field: learnings
  Who Writes: Auto/agent (Vec)
  Why It Matters: Curated gotchas — "auth middleware expects {user: User}, not
    {userId}" — prevents repeating mistakes
  ────────────────────────────────────────
  Field: dependencies
  Who Writes: Agent/human (Vec)
  Why It Matters: External constraints — "depends on database feature for users
    table"
  ────────────────────────────────────────
  Field: current_state
  Who Writes: Auto-populated
  Why It Matters: "3/7 tasks done. Login form complete. Token refresh in
    progress." — updated every iteration
  The existing knowledge_paths and context_files get wired up with full CRUD.

  Key design choices:
  - Agents write everything — braindump agent fills
  description/architecture/boundaries on creation, review agent refines them
  over time, auto-accumulation handles context_files and current_state
  - Token budget strategy — always inject description + architecture +
  boundaries + dependencies + current_state (~500-1500 tokens). Learnings: top
  10. File contents: via MCP on demand.
  - Two RAG embedding levels — Level 1: feature snapshot (all text fields
  combined, re-embedded on update). Level 2: iteration history per Doc 017
  (per-iteration entries).
  - Steps 1-6 work without Qdrant/Ollama — the entity redesign makes prompt
  building better immediately. RAG is the cherry on top.

✻ Cooked for 6m 36s

❯ You must think about all the future consequenses of these data design...  
  and find out if this doesn't provide issues based on all the flaws and    
  imperfections of LLM agents etc etc.. proactively find bugs and fill gaps 
   in this design                                                           

● sequential-thinking - sequentialthinking (MCP)(thought: "Let me systematically
                                                 identify every failure mode of
                                                this Feature entity design when
                                                interacting with real LLM
                                                agents. I need to think about:
                                                agent hallucination,
                                                overwriting, context drift,
                                                unbounded growth, concurrency,
                                                trust boundaries, format
                                                violations, embedding quality
                                                degradation, and more. Let me
                                                start by categorizing the
                                                failure classes.\n\nCLASS 1:
                                                AGENT OVERWRITING / DESTRUCTIVE
                                                UPDATES\nThe biggest risk.
                                                update_feature replaces ALL
                                                fields. If an agent updates
                                                description, it might also
                                                accidentally blank out learnings
                                                 or context_files because it
                                                didn't include them in the
                                                update payload.\n\nCurrent
                                                design says: \"CRUD allows full
                                                field updates — No more preserve
                                                 knowledge_paths on update. If
                                                the agent sends knowledge_paths
                                                in an update, it replaces the
                                                old list. The agent is the
                                                authority.\"\n\nThis is
                                                DANGEROUS. Agents are not
                                                reliable authorities. A Haiku
                                                iteration that updates
                                                description might not know about
                                                 learnings that accumulated over
                                                 20 iterations. It would wipe
                                                them.", nextThoughtNeeded: true,
                                                 thoughtNumber: 1,
                                                totalThoughts: 12)
  ⎿  {
       "thoughtNumber": 1,
       "totalThoughts": 12,
     … +4 lines (ctrl+o to expand)

● sequential-thinking - sequentialthinking (MCP)(thought: "CLASS 2: UNBOUNDED
                                                GROWTH\n- learnings: Vec<String>
                                                 — agents love to add learnings.
                                                 After 100 iterations, you could
                                                 have 300 \"learnings\" where
                                                80% are duplicates or trivially
                                                obvious (\"remember to import
                                                the module\"). No deduplication.
                                                 No relevance scoring. No
                                                pruning.\n- context_files:
                                                auto-grows from files_touched. A
                                                 feature that touches 200 files
                                                over its lifetime gets 200
                                                context_files. Most are
                                                irrelevant (e.g., package.json,
                                                config files touched once).\n-
                                                description/architecture: agents
                                                 may keep appending rather than
                                                replacing, turning a 200-token
                                                description into a 5000-token
                                                ramble.\n- dependencies: similar
                                                 growth problem.\n\nEach of
                                                these blows the token budget.
                                                The doc says \"target <4000
                                                tokens injected\" but nothing
                                                enforces this.\n\nCLASS 3:
                                                HALLUCINATED CONTENT\nAgents
                                                writing Feature fields can
                                                hallucinate:\n- architecture
                                                that doesn't match actual
                                                code\n- boundaries that are
                                                wrong (feature actually does
                                                handle OAuth)\n- learnings that
                                                are incorrect (\"auth uses
                                                localStorage\" when it actually
                                                uses memory)\n- dependencies
                                                that don't exist\n\nHallucinated
                                                 learnings are especially
                                                dangerous — they become \"DO NOT
                                                 repeat these mistakes\" in
                                                prompts, guiding future
                                                iterations AWAY from correct
                                                approaches.", nextThoughtNeeded:
                                                 true, thoughtNumber: 2,
                                                totalThoughts: 12)
  ⎿  {
       "thoughtNumber": 2,
       "totalThoughts": 12,
     … +4 lines (ctrl+o to expand)

● sequential-thinking - sequentialthinking (MCP)(thought: "CLASS 4: STALE DATA /
                                                 REALITY DRIFT\n- description
                                                says \"JWT-based auth\" but an
                                                agent switched to session-based
                                                auth 10 iterations ago and
                                                nobody updated description\n-
                                                architecture says \"three
                                                layers\" but refactoring removed
                                                 one layer\n- context_files
                                                lists src/lib/auth.ts but it was
                                                 renamed to
                                                src/lib/authentication.ts\n-
                                                current_state says \"3/7 tasks
                                                complete\" but it's actually 5/7
                                                 because auto-update failed\n-
                                                boundaries say \"OUT OF SCOPE:
                                                OAuth\" but a task was added for
                                                 OAuth\n\nThis is the staleness
                                                problem that the anti-RAG
                                                articles warned about. Feature
                                                data becomes a lie that misleads
                                                 future iterations.\n\nCLASS 5:
                                                CONCURRENCY / RACE CONDITIONS\n-
                                                 Two iterations running on same
                                                feature (if concurrent loops
                                                ever happen — Doc 011 envisions
                                                this)\n- Both read Feature, both
                                                 modify learnings, last write
                                                wins, first write's learnings
                                                lost\n- auto-accumulation
                                                (update current_state) races
                                                with agent update (update
                                                description)\n- Even with file
                                                locking, the
                                                \"read-modify-write\" pattern
                                                means stale reads\n\nCLASS 6:
                                                AGENT WRITING TO WRONG
                                                FEATURE\n- Haiku is told to work
                                                 on \"authentication\" task but
                                                accidentally modifies
                                                \"payments\" feature fields\n-
                                                context_files from auth work get
                                                 appended to payments feature\n-
                                                 learnings about auth get stored
                                                 on payments feature\n- This
                                                poisons the payments feature's
                                                context", nextThoughtNeeded:
                                                true, thoughtNumber: 3,
                                                totalThoughts: 12)
  ⎿  {
       "thoughtNumber": 3,
       "totalThoughts": 12,
     … +4 lines (ctrl+o to expand)

● sequential-thinking - sequentialthinking (MCP)(thought: "CLASS 7: EMBEDDING
                                                QUALITY DEGRADATION\n- If
                                                description is \"JWT-based
                                                auth\" (one line), the embedding
                                                 is thin and matches poorly\n-
                                                If description is 3000 tokens of
                                                 rambling, the embedding is
                                                diluted — too many concepts in
                                                one vector\n- If learnings
                                                contain hallucinated facts, the
                                                embedding encodes wrong
                                                information, and semantic search
                                                 returns misleading results\n-
                                                If current_state is stale, the
                                                feature snapshot embedding
                                                represents a past state, not
                                                present\n- Duplicate/redundant
                                                learnings create embedding
                                                noise\n\nCLASS 8: MCP TOOL
                                                MISUSE\n- Agent calls
                                                search_feature_memory(\"*\") or
                                                empty string — what happens?\n-
                                                Agent ignores MCP tools entirely
                                                 and works from injected context
                                                 only (wasted setup)\n- Agent
                                                calls search_feature_memory 50
                                                times in one iteration, burning
                                                tokens on MCP overhead\n- Agent
                                                treats MCP results as ground
                                                truth even when they're stale
                                                iteration data\n\nCLASS 9:
                                                FORMAT VIOLATIONS\n- Agent
                                                writes YAML-unsafe characters in
                                                 learnings (e.g., unescaped
                                                colons, quotes)\n- Agent writes
                                                description with markdown that
                                                confuses YAML parser\n- Agent
                                                writes file paths in
                                                context_files that don't exist
                                                or are absolute instead of
                                                relative\n- Agent writes
                                                boundaries as free-form text
                                                instead of IN SCOPE / OUT OF
                                                SCOPE format\n\nCLASS 10:
                                                CIRCULAR DEPENDENCY BETWEEN
                                                FEATURES AND PROMPTS\n- Feature
                                                data goes into prompt\n- Agent
                                                updates Feature based on what it
                                                 read in prompt\n- Next
                                                iteration reads updated Feature
                                                into prompt\n- Agent
                                                \"confirms\" its own changes,
                                                amplifying errors\n-
                                                Hallucinated learning → injected
                                                 into prompt → agent sees it as
                                                ground truth → reinforces
                                                it\n\nThis is a feedback loop
                                                that can amplify errors across
                                                iterations.", nextThoughtNeeded:
                                                 true, thoughtNumber: 4,
                                                totalThoughts: 12)
  ⎿  {
       "thoughtNumber": 4,
       "totalThoughts": 12,
     … +4 lines (ctrl+o to expand)

● sequential-thinking - sequentialthinking (MCP)(thought: "Now let me design
                                                mitigations for each class.
                                                Starting with the most
                                                critical.\n\nMITIGATION FOR
                                                CLASS 1 (Destructive
                                                Overwrites):\nThe doc says
                                                \"CRUD allows full field
                                                updates.\" This is wrong. Need
                                                two update patterns:\n1. PATCH
                                                semantics — only update fields
                                                that are explicitly provided.
                                                Omitted fields are
                                                preserved.\n2. APPEND operations
                                                 — learnings, context_files,
                                                dependencies should have
                                                dedicated append-only
                                                operations, not
                                                replace-all.\n\nSpecifically:\n-
                                                 update_feature should use
                                                PATCH: only overwrite fields
                                                that are present in the input
                                                (using Option wrappers where
                                                None means \"don't change\")\n-
                                                append_feature_learning (already
                                                 proposed) — append only\n-
                                                add_feature_context_file
                                                (already proposed) — add only\n-
                                                 remove_feature_learning(index)
                                                — explicit removal\n- remove_fea
                                                ture_context_file(path) —
                                                explicit removal\n\nAgents
                                                CANNOT replace the learnings
                                                list wholesale. They can only
                                                append or request removal. This
                                                prevents accidental
                                                wipes.\n\nCRITICAL: The
                                                YAML-editing path (agents edit
                                                features.yaml directly) BYPASSES
                                                 all these protections. If an
                                                agent edits the YAML file and
                                                forgets to include learnings,
                                                they're gone. Mitigation: Ralph
                                                validates the YAML after each
                                                iteration — if key fields shrunk
                                                 significantly (learnings count
                                                dropped by >50%), flag it as
                                                suspicious and potentially roll
                                                back.", nextThoughtNeeded: true,
                                                 thoughtNumber: 5,
                                                totalThoughts: 12)
  ⎿  {
       "thoughtNumber": 5,
       "totalThoughts": 12,
     … +4 lines (ctrl+o to expand)

● sequential-thinking - sequentialthinking (MCP)(thought: "MITIGATION FOR CLASS
                                                2 (Unbounded
                                                Growth):\n\nlearnings:\n- Max 50
                                                 items. When appending the 51st,
                                                 remove the oldest.\n- BUT: old
                                                learnings might be more
                                                important than new ones. Better:
                                                 cap at 50, and on overflow, use
                                                 Opus review to consolidate
                                                (merge duplicates, remove
                                                obsolete ones, keep critical
                                                ones).\n- Short-term fix: hard
                                                cap + overflow warning in
                                                logs.\n- Each learning has a max
                                                 length (500 chars). Agents
                                                write novels;
                                                truncate.\n\ncontext_files:\n-
                                                Max 30 files. Auto-accumulation
                                                from files_touched only adds
                                                files touched 3+ times AND that
                                                still exist on disk.\n- On
                                                overflow: keep the
                                                most-frequently-touched files,
                                                drop the least-touched.\n-
                                                Validate on read: skip files
                                                that no longer exist (stale path
                                                 cleanup).\n\ndescription/archit
                                                ecture:\n- Max 2000 chars each.
                                                Truncate on write. Agent can't
                                                make it longer.\n- Better: Ralph
                                                 counts tokens and warns if
                                                Feature context exceeds
                                                budget.\n\ndependencies:\n- Max
                                                20 items. Reasonable
                                                cap.\n\ncurrent_state:\n- Max
                                                500 chars. Auto-generated,
                                                controlled by Ralph, not
                                                agent-writable
                                                directly.\n\nMITIGATION FOR
                                                CLASS 3 (Hallucinated
                                                Content):\n\nThis is the hardest
                                                 one. You can't prevent
                                                hallucination. You can only:\n1.
                                                 VALIDATE learnings against
                                                reality when possible. E.g., if
                                                learning says \"file X uses Y
                                                pattern\", check if file X
                                                exists.\n2. EXPIRE learnings.
                                                Each learning gets a timestamp.
                                                Learnings older than N
                                                iterations get flagged for
                                                re-verification during Opus
                                                review.\n3. PROVENANCE tracking.
                                                 Each learning has a source:
                                                \"auto-extracted from iteration
                                                7\" vs \"human-written\" vs
                                                \"opus-reviewed\". Human-written
                                                 and opus-reviewed learnings are
                                                 more trustworthy.\n4. SURFACE,
                                                DON'T ENFORCE. Learnings are
                                                presented as \"previous
                                                observations\" not \"absolute
                                                truths.\" Prompt wording
                                                matters: \"Previous iterations
                                                noted:\" not \"CRITICAL: DO NOT
                                                violate these rules.\"",
                                                nextThoughtNeeded: true,
                                                thoughtNumber: 6, totalThoughts:
                                                 12)
  ⎿  {
       "thoughtNumber": 6,
       "totalThoughts": 12,
     … +4 lines (ctrl+o to expand)

● sequential-thinking - sequentialthinking (MCP)(thought: "MITIGATION FOR CLASS
                                                4 (Stale Data / Reality
                                                Drift):\n\ncontext_files
                                                staleness:\n- On prompt build:
                                                validate each file exists. Skip
                                                missing files with a note:
                                                \"[STALE: src/lib/auth.ts no
                                                longer exists]\"\n- Periodic
                                                cleanup: during Opus review,
                                                validate all context_files and
                                                knowledge_paths. Remove stale on
                                                es.\n\ndescription/architecture
                                                staleness:\n- Can't
                                                auto-validate prose against
                                                reality.\n- Mitigation: Opus
                                                review prompt includes:
                                                \"Compare the Feature
                                                description and architecture
                                                fields against the ACTUAL code
                                                you can see. Update any fields
                                                that are inaccurate.\"\n- Add a
                                                `last_verified` timestamp on
                                                Feature. If >10 iterations since
                                                 last verification, prompt Opus
                                                to re-verify.\n\ncurrent_state
                                                staleness:\n- This MUST be
                                                auto-generated, not
                                                agent-writable. Ralph computes
                                                it from task statuses every time
                                                 it's needed.\n- Making it a
                                                computed field (generated at
                                                read time) instead of a stored
                                                field would prevent staleness
                                                entirely.\n- BUT: then it can't
                                                be embedded in Qdrant (no stable
                                                 text to embed).\n- COMPROMISE:
                                                stored field, but
                                                auto-regenerated by Ralph before
                                                 every loop iteration. Agents
                                                cannot write to
                                                it.\n\nboundaries staleness:\n-
                                                Less likely to drift (scope
                                                decisions are stable).\n- Opus
                                                review should validate: \"Are
                                                the boundaries still accurate?
                                                Has scope
                                                changed?\"\n\nMITIGATION FOR
                                                CLASS 5
                                                (Concurrency):\n\nCurrent
                                                architecture: one loop at a
                                                time. File locking (fs2)
                                                protects YAML writes.\nFuture
                                                (Doc 011): concurrent loops on
                                                different features. Each loop
                                                locks a different
                                                feature.\nRisk: two loops on
                                                SAME feature (shouldn't happen
                                                but could via
                                                bug).\n\nMitigation:\n-
                                                Feature-level lock field:
                                                `locked_by: Option<String>`
                                                (loop ID). Ralph sets on loop
                                                start, clears on loop end.\n- If
                                                 a loop tries to claim a feature
                                                 already locked, it skips and
                                                picks a different task.\n- This
                                                is a future concern for Doc 011,
                                                 not needed for Phase 0-2.",
                                                nextThoughtNeeded: true,
                                                thoughtNumber: 7, totalThoughts:
                                                 12)
  ⎿  {
       "thoughtNumber": 7,
       "totalThoughts": 12,
     … +4 lines (ctrl+o to expand)

● sequential-thinking - sequentialthinking (MCP)(thought: "MITIGATION FOR CLASS
                                                6 (Wrong Feature):\n\nThis is
                                                actually handled by the design:
                                                Ralph selects the task, Ralph
                                                knows the feature, Ralph routes
                                                memory to the correct feature
                                                collection. The agent doesn't
                                                choose which feature to update —
                                                 Ralph does.\n\nBUT: agents can
                                                still edit features.yaml
                                                directly. If an agent is told
                                                \"work on task 42 (feature:
                                                auth)\" but while working, it
                                                decides to also update the
                                                payments feature description in
                                                features.yaml... Ralph can't
                                                prevent this.\n\nMitigation:\n-
                                                Post-iteration validation: Ralph
                                                 diffs features.yaml
                                                before/after iteration. If a
                                                feature OTHER than the target
                                                feature was modified, log a
                                                warning. Optionally: reject the
                                                change and restore from
                                                backup.\n- This uses the
                                                existing CLAUDE.md
                                                backup/restore mechanism (backup
                                                 on loop start, restore on
                                                stop).\n\nMITIGATION FOR CLASS 7
                                                 (Embedding Quality):\n\nThin
                                                embeddings:\n- Enforce minimum
                                                description length? No — forcing
                                                 length creates padding. Better:
                                                 the braindump agent prompt
                                                explicitly asks for rich
                                                descriptions.\n- If description
                                                is <100 chars, DON'T embed. Mark
                                                 feature as \"insufficient
                                                context.\"\n\nDiluted embeddings
                                                 (too long):\n- Cap at 2000
                                                chars per field. Combined
                                                embedding text max ~6000
                                                chars.\n- This is fine for
                                                nomic-embed-text which handles
                                                up to 8191
                                                tokens.\n\nHallucinated content
                                                in embeddings:\n- Can't filter.
                                                But: semantic search returns
                                                results with scores.
                                                Low-confidence results (score
                                                0.4-0.5) should be presented as
                                                \"possibly relevant\" not
                                                \"definitely
                                                relevant.\"\n\nStale
                                                embeddings:\n- Re-embed on every
                                                 Feature update. Ralph tracks
                                                `embedding_hash` — SHA256 of the
                                                 combined text. Only re-embed if
                                                 hash changed.\n\nMITIGATION FOR
                                                 CLASS 8 (MCP Misuse):\n\nEmpty
                                                queries:\n- MCP server
                                                validates: query must be >3
                                                chars. Return error for
                                                empty/trivial queries.\n\nAgent
                                                ignores MCP:\n- Fine. The base
                                                prompt injection provides core
                                                context. MCP is
                                                supplementary.\n- Don't rely on
                                                MCP for critical context. Always
                                                 inject description +
                                                boundaries.\n\nAgent
                                                over-queries:\n- MCP server
                                                tracks call count per session.
                                                After 10 calls, return a hint:
                                                \"You've made many searches.
                                                Consider using the results you
                                                have.\"\n- This is a soft limit,
                                                 not a hard block.\n\nAgent
                                                trusts stale MCP data:\n- MCP
                                                results include timestamps.
                                                Prompt includes: \"Note: search
                                                results are from previous
                                                iterations and may be
                                                outdated.\"", nextThoughtNeeded:
                                                 true, thoughtNumber: 8,
                                                totalThoughts: 12)
  ⎿  {
       "thoughtNumber": 8,
       "totalThoughts": 12,
     … +4 lines (ctrl+o to expand)

● sequential-thinking - sequentialthinking (MCP)(thought: "MITIGATION FOR CLASS
                                                9 (Format Violations):\n\nYAML
                                                safety:\n- ALL string fields
                                                written via IPC (Rust code) are
                                                safe — serde_yaml handles
                                                escaping.\n- The risk is agents
                                                editing features.yaml DIRECTLY.
                                                They might write malformed
                                                YAML.\n- Mitigation: Ralph
                                                validates YAML after each
                                                iteration. If parse fails,
                                                restore from pre-iteration
                                                backup.\n- This is already
                                                partially handled by the
                                                stagnation check (reads files),
                                                but should be explicit
                                                validation.\n\nFile path
                                                validation:\n- context_files and
                                                 knowledge_paths: validate paths
                                                 are relative (not absolute),
                                                don't contain .., and use
                                                forward slashes.\n- On prompt
                                                build: verify files exist before
                                                 injecting. Skip missing files
                                                with a note.\n\nCharacter
                                                limits:\n- Enforce max lengths
                                                on write: description (2000),
                                                architecture (2000), boundaries
                                                (1000), each learning (500),
                                                each dependency (200),
                                                current_state (500).\n- Truncate
                                                 with \"[truncated]\" suffix
                                                rather than
                                                rejecting.\n\nMITIGATION FOR
                                                CLASS 10 (Feedback Loop / Error
                                                Amplification):\n\nThis is the
                                                most insidious failure mode. A
                                                hallucinated learning enters the
                                                 Feature, gets injected into
                                                prompts, agents treat it as
                                                truth, and it persists
                                                forever.\n\nMitigations:\n1.
                                                PROVENANCE on learnings. Each
                                                learning is tagged: { text,
                                                source, iteration, verified }\n
                                                  - source: \"auto\" (extracted
                                                from iteration output),
                                                \"agent\" (written by agent),
                                                \"human\" (written by human),
                                                \"opus_reviewed\" (verified by
                                                Opus)\n   - Only
                                                \"opus_reviewed\" and \"human\"
                                                learnings should be presented
                                                with high confidence.\n   -
                                                \"auto\" learnings are presented
                                                 as \"Observation from iteration
                                                 N (unverified):\"\n\n2. EXPIRY
                                                on auto-generated learnings.
                                                After 20 iterations without
                                                re-verification, auto-learnings
                                                get a staleness warning:
                                                \"[STALE - unverified since
                                                iteration 5]\"\n\n3.
                                                VERIFICATION CYCLE. Every N
                                                iterations (e.g., every 5th Opus
                                                 review), Opus is prompted:
                                                \"Review and verify the
                                                feature's learnings. Remove any
                                                that are incorrect or outdated.
                                                Mark remaining ones as
                                                verified.\"\n\n4. PROMPT FRAMING
                                                 matters enormously:\n   BAD:
                                                \"## CRITICAL RULES - DO NOT
                                                VIOLATE: {learnings}\"\n   GOOD:
                                                 \"## Observations from previous
                                                 iterations (verify before
                                                relying on these):
                                                {learnings}\"\n   \n   The
                                                framing determines whether the
                                                agent treats learnings as
                                                absolute truth or as hints to
                                                verify.", nextThoughtNeeded:
                                                true, thoughtNumber: 9,
                                                totalThoughts: 12)
  ⎿  {
       "thoughtNumber": 9,
       "totalThoughts": 12,
     … +4 lines (ctrl+o to expand)

● sequential-thinking - sequentialthinking (MCP)(thought: "Let me now think
                                                about ADDITIONAL issues I
                                                haven't categorized
                                                yet.\n\nCLASS 11: LEARNING
                                                DEDUPLICATION\nAgents will
                                                repeatedly generate the same
                                                learning. \"Auth middleware
                                                expects User object\" will
                                                appear 5 times if 5 iterations
                                                hit the same issue. The
                                                learnings list becomes
                                                repetitive
                                                noise.\n\nMitigation:\n- Before
                                                appending a learning, do a
                                                simple string similarity check
                                                (not embedding — too expensive
                                                for a write-path operation).
                                                Could use Levenshtein distance
                                                or even just check if any
                                                existing learning contains >80%
                                                of the same words.\n- Simpler:
                                                normalize and dedup exact
                                                matches (lowercase, trim
                                                whitespace).\n- Best:
                                                append_feature_learning checks
                                                for near-duplicates before
                                                adding. If a similar learning
                                                exists, increment a
                                                \"hit_count\" on it instead of
                                                adding a new one. Learnings with
                                                 higher hit_count are more
                                                likely to be real.\n\nCLASS 12:
                                                current_state AS COMPUTED VS
                                                STORED\nThe doc proposes
                                                current_state as a stored field
                                                that Ralph auto-updates. But:\n-
                                                 If Ralph crashes between
                                                updating tasks and updating
                                                current_state, they're out of
                                                sync.\n- If an agent changes
                                                task statuses in YAML,
                                                current_state doesn't update
                                                until next iteration.\n\nBetter
                                                design: current_state is
                                                COMPUTED at prompt-build time
                                                from task statuses. Never stored
                                                 in YAML. For RAG embedding:
                                                computed when the Feature
                                                snapshot is embedded.\n\nBut
                                                wait — this means current_state
                                                can't be agent-enriched. An
                                                agent might want to say \"Login
                                                form done but has known
                                                accessibility issues\" — that's
                                                richer than a computed \"1/7
                                                tasks done.\"\n\nCOMPROMISE:
                                                current_state is computed from
                                                task statuses PLUS an optional
                                                agent-written
                                                current_state_notes field for
                                                qualitative additions. The
                                                computed part is always
                                                accurate; the notes part may be
                                                stale.\n\nActually, simpler:
                                                just compute it. If the agent
                                                has qualitative notes, they go
                                                into learnings (\"accessibility
                                                issues remain in LoginForm\").
                                                current_state should be purely
                                                structural/computed.\n\nCLASS
                                                13: KNOWLEDGE_PATHS FILE SIZE
                                                EXPLOSION\nknowledge_paths
                                                points to docs/specs. A spec
                                                could be 50KB. The prompt
                                                builder does fs::read_to_string
                                                and injects it. Three 50KB specs
                                                 = 150KB = ~37,500 tokens. This
                                                blows any token
                                                budget.\n\nMitigation:\n- On
                                                prompt build: measure each
                                                file's size. If total
                                                knowledge_paths content > 4000
                                                tokens, switch to MCP-only
                                                (don't inject, let Claude pull
                                                on demand).\n- Or: inject a
                                                SUMMARY of the file (first 500
                                                chars + \"... [full document
                                                available via MCP]\").\n- Or:
                                                pre-compute a summary once when
                                                the knowledge_path is added,
                                                store the summary alongside the
                                                path.\n\nI think the simplest
                                                is: inject if <2000 tokens per
                                                file, otherwise truncate with
                                                MCP hint.", nextThoughtNeeded:
                                                true, thoughtNumber: 10,
                                                totalThoughts: 12)
  ⎿  {
       "thoughtNumber": 10,
       "totalThoughts": 12,
     … +4 lines (ctrl+o to expand)

● sequential-thinking - sequentialthinking (MCP)(thought: "CLASS 14: THE
                                                LEARNING STRUCT NEEDS TO BE
                                                RICHER\nThe doc proposes
                                                learnings: Vec<String>. But per
                                                the mitigations above, each
                                                learning needs:\n- text (the
                                                actual learning)\n- source (auto
                                                /agent/human/opus_reviewed)\n-
                                                iteration (which iteration it
                                                came from)\n- created
                                                (timestamp)\n- hit_count (how
                                                many times this was
                                                re-observed)\n- verified (bool —
                                                 has Opus confirmed
                                                this?)\n\nThis means learnings
                                                should NOT be Vec<String>. It
                                                should be Vec<FeatureLearning>
                                                where FeatureLearning is a
                                                struct.\n\nSimilarly,
                                                context_files might benefit from
                                                 being Vec<FeatureContextFile>
                                                with:\n- path (the file path)\n-
                                                 source (auto/human)\n-
                                                touch_count (times touched
                                                across iterations)\n-
                                                last_touched (iteration
                                                number)\n\nAnd dependencies
                                                might benefit from being
                                                Vec<FeatureDependency> with:\n-
                                                description (the dependency
                                                text)\n- feature (optional — if
                                                it depends on another
                                                feature)\n- external (bool — is
                                                this an external system?)\n\nBUT
                                                 WAIT. There's a tension here
                                                with the YAML editing path. If
                                                agents edit features.yaml
                                                directly, they need to write
                                                these rich structs. Agents are
                                                TERRIBLE at writing complex
                                                nested YAML. They'll mess up the
                                                 structure.\n\nTwo choices:\n1.
                                                Keep it simple (Vec<String>) and
                                                 accept the limitations\n2. Use
                                                rich structs but only allow
                                                modification via IPC
                                                (append_feature_learning), not
                                                direct YAML editing\n\nChoice 2
                                                is better for data quality but
                                                creates a problem: the current
                                                architecture has agents editing
                                                .ralph/db/ files directly. If
                                                learnings is a complex struct,
                                                agents will corrupt
                                                it.\n\nRESOLUTION: Learnings
                                                should have a rich internal
                                                representation but a SIMPLE
                                                external representation in YAML.
                                                 When an agent writes a plain
                                                string to learnings in YAML,
                                                Ralph upgrades it to a
                                                FeatureLearning struct on next
                                                load with defaults (source:
                                                agent, verified: false,
                                                hit_count: 1, created:
                                                now).\n\nThis is similar to how
                                                serde handles optional fields
                                                with defaults. The YAML can be
                                                simple:\n\n```yaml\nlearnings:\n
                                                  - \"Auth middleware expects
                                                User object\"\n  - text: \"Token
                                                 refresh must happen before
                                                401\"\n    source:
                                                opus_reviewed\n    verified:
                                                true\n```\n\nBoth forms
                                                deserialize correctly using
                                                serde's untagged enum or custom
                                                deserializer.",
                                                nextThoughtNeeded: true,
                                                thoughtNumber: 11,
                                                totalThoughts: 12)
  ⎿  {
       "thoughtNumber": 11,
       "totalThoughts": 12,
     … +4 lines (ctrl+o to expand)

● sequential-thinking - sequentialthinking (MCP)(thought: "CLASS 15: THE
                                                DESCRIPTION/ARCHITECTURE
                                                DISTINCTION IS FRAGILE\nAgents
                                                won't consistently separate
                                                \"description\" from
                                                \"architecture.\" They'll put
                                                architecture details in
                                                description and vice versa.
                                                Having two fields that are
                                                conceptually similar creates
                                                confusion.\n\nOptions:\nA. Merge
                                                 them: one \"overview\" field
                                                that contains both domain
                                                description and architecture\nB.
                                                 Keep separate but accept
                                                overlap and don't enforce
                                                boundaries\nC. Give very clear
                                                prompt instructions about what
                                                goes where\n\nI think A is wrong
                                                 (loses structure), C is
                                                unreliable (agents drift). B is
                                                pragmatic.\n\nFor RAG embedding:
                                                 they're concatenated anyway, so
                                                 overlap doesn't hurt embedding
                                                quality. For prompt injection:
                                                both are always injected, so
                                                overlap just means slightly more
                                                 tokens.\n\nVERDICT: Keep
                                                separate. Accept overlap. The
                                                value is in having a PLACE to
                                                put architecture info, even if
                                                some ends up in
                                                description.\n\nCLASS 16: WHAT
                                                ABOUT FEATURE DELETION?\nWhen a
                                                feature is deleted:\n- Qdrant
                                                collection needs to be
                                                dropped\n- Feature snapshot
                                                embedding needs to be removed\n-
                                                 But tasks still reference the
                                                feature\n\nCurrently:
                                                delete_feature blocks if tasks
                                                exist. Good.\nBut after
                                                deletion: Qdrant data persists
                                                until explicitly
                                                cleaned.\n\nMitigation:
                                                delete_feature also triggers
                                                MemoryStore::delete_collection()
                                                .\n\nCLASS 17: FEATURE
                                                RENAME\nCurrently: name is
                                                immutable (preserved on update).
                                                 Good.\nBut display_name and
                                                acronym can change. These appear
                                                 in EnrichedTask joins.\nNot a
                                                data design issue, but worth
                                                noting.\n\nFINAL SUMMARY OF
                                                CHANGES NEEDED TO DOC 018:\n\n1.
                                                 PATCH semantics for
                                                update_feature (not full
                                                replace)\n2. Learnings as
                                                Vec<FeatureLearning> with
                                                provenance, not Vec<String>\n3.
                                                current_state as COMPUTED field,
                                                 not stored\n4. Caps on all
                                                collections (learnings: 50,
                                                context_files: 30, dependencies:
                                                 20)\n5. Caps on all text fields
                                                 (description: 2000,
                                                architecture: 2000, boundaries:
                                                1000)\n6. Near-duplicate
                                                detection for learnings\n7.
                                                Staleness detection for
                                                context_files (validate files
                                                exist)\n8. Post-iteration
                                                Feature validation (detect
                                                destructive agent edits)\n9.
                                                Prompt framing: \"observations\"
                                                 not \"rules\" for
                                                learnings\n10. knowledge_paths
                                                file size handling (truncate +
                                                MCP fallback)\n11. YAML backward
                                                 compat for learnings (string OR
                                                 struct)\n12. Re-embedding
                                                triggers and hash-based
                                                dedup\n13. Opus verification
                                                cycle for learnings",
                                                nextThoughtNeeded: false,
                                                thoughtNumber: 12,
                                                totalThoughts: 12)
  ⎿  {
       "thoughtNumber": 12,
       "totalThoughts": 12,
     … +4 lines (ctrl+o to expand)

● Found 17 failure classes. Let me update the doc with all mitigations.

● Read 1 file (ctrl+o to expand)

● Now I have the full doc. Let me add the comprehensive failure analysis and
  mitigations.

● Update(.docs/018_FEATURE_ENTITY_REDESIGN_FOR_RAG.md)
  ⎿  Added 4 lines, removed 7 lines
      132      // === Accumulated Knowledge (new) ===
      133  
      134      /// Key learnings accumulated over iterations.
      135 -    /// Agent-written summaries of important discoveries, gotc
          -has, patterns.                                                
      136 -    /// NOT raw iteration logs — curated insights.            
      135 +    /// Rich struct with provenance tracking — prevents halluc
          +ination amplification.                                        
      136      /// Written by: review agent (periodic), auto-extraction (
           from iteration outcomes)
      137      /// Read by: prompt builder (injected), RAG (embedded)
      139 -    /// Example:                                              
      140 -    ///   - "Auth middleware expects { user: User } on req, no
          -t { userId: string }"                                         
      141 -    ///   - "Token refresh must happen before the 401 response
          - reaches React Query"                                         
      142 -    ///   - "The users table has a unique index on email, not 
          -username"                                                     
      138 +    /// YAML supports BOTH simple strings and full structs (se
          +e FeatureLearning).                                           
      139 +    /// Max 50 items. On overflow, oldest unverified items are
          + pruned.                                                      
      140      #[serde(default, skip_serializing_if = "Vec::is_empty")]
      144 -    pub learnings: Vec<String>,                               
      141 +    pub learnings: Vec<FeatureLearning>,                      
      142  
      143      /// Dependencies on external systems, APIs, or other featu
           res.
      144      /// Written by: braindump agent, human, agents during exec
           ution

● Update(.docs/018_FEATURE_ENTITY_REDESIGN_FOR_RAG.md)
  ⎿  Added 45 lines, removed 8 lines
      150      #[serde(default, skip_serializing_if = "Vec::is_empty")]
      151      pub dependencies: Vec<String>,
      152  
      153 -    // === Progress Tracking (new, auto-populated) ===        
      153 +    // === Progress Tracking (COMPUTED, never stored) ===     
      154 +    // current_state is NOT a stored field.                   
      155 +    // It is COMPUTED at read time from task statuses.        
      156 +    // See "current_state as Computed Field" section below.   
      157 +}                                                             
      158 +```                                                           
      159  
      155 -    /// Current implementation status — auto-generated from ta
          -sk completions.                                               
      156 -    /// Written by: Ralph (auto-updated after each iteration) 
      157 -    /// Read by: prompt builder (injected), frontend (display)
      158 -    /// Example: "3/7 tasks complete. Login form done. Token r
          -efresh in progress.                                           
      159 -    /// Logout and session management pending."               
      160 -    #[serde(skip_serializing_if = "Option::is_none")]         
      161 -    pub current_state: Option<String>,                        
      160 +### FeatureLearning Struct                                    
      161 +                                                              
      162 +```rust                                                       
      163 +/// A single learning with provenance tracking.               
      164 +/// Supports dual YAML representation:                        
      165 +///   Simple:  "Auth middleware expects User object"          
      166 +///   Full:    { text: "...", source: opus_reviewed, verified:
          + true, ... }                                                  
      167 +/// Simple strings auto-upgrade to FeatureLearning on deserial
          +ization.                                                      
      168 +#[derive(Debug, Clone, Serialize, Deserialize)]               
      169 +#[serde(untagged)]                                            
      170 +pub enum FeatureLearning {                                    
      171 +    /// Agent or human wrote a plain string in YAML           
      172 +    Simple(String),                                           
      173 +    /// Full provenance-tracked learning                      
      174 +    Rich {                                                    
      175 +        text: String,                                         
      176 +        #[serde(default = "default_learning_source")]         
      177 +        source: LearningSource,                               
      178 +        #[serde(skip_serializing_if = "Option::is_none")]     
      179 +        iteration: Option<u32>,                               
      180 +        #[serde(skip_serializing_if = "Option::is_none")]     
      181 +        created: Option<String>,                              
      182 +        #[serde(default)]                                     
      183 +        hit_count: u32,                                       
      184 +        #[serde(default)]                                     
      185 +        verified: bool,                                       
      186 +    },                                                        
      187  }
      188 +                                                              
      189 +#[derive(Debug, Clone, Serialize, Deserialize)]               
      190 +#[serde(rename_all = "snake_case")]                           
      191 +pub enum LearningSource {                                     
      192 +    Auto,          // Extracted from iteration output         
      193 +    Agent,         // Written by agent                        
      194 +    Human,         // Written by human via UI                 
      195 +    OpusReviewed,  // Verified by Opus review                 
      196 +}                                                             
      197  ```
      198  
      199 +**Why dual representation?** Agents editing `features.yaml` di
          +rectly will write plain strings. They're terrible at complex n
          +ested YAML. Ralph upgrades Simple → Rich on the IPC write path
          + with defaults (`source: auto`, `verified: false`, `hit_count:
          + 1`, `created: now`). Both forms round-trip cleanly through se
          +rde.                                                          
      200 +```                                                           
      201 +                                                              
      202  ### Field Summary
      203  
      204  | Field | Type | Who Writes | Who Reads | RAG Embed? | Prompt 
           Inject? | MCP Resource? |

● Now let me add the massive failure analysis section and update the resolved
  decisions. I'll append after the open questions.

● Update(.docs/018_FEATURE_ENTITY_REDESIGN_FOR_RAG.md)
  ⎿  Added 375 lines, removed 10 lines
       632  
       633  Steps 1-6 can proceed **without** Qdrant/Ollama. They make fe
            atures useful for prompt building immediately. Steps 7-8 add 
            RAG on top.
       634  
       635 -## Resolved Decisions                                        
       635 +## current_state as Computed Field                           
       636  
       637 -1. **Feature.description is long-form** — NOT a one-liner. Ag
           -ents write multi-paragraph descriptions. This is the primary 
           -embedding text.                                              
       637 +`current_state` is **NOT stored in features.yaml**. It is com
           +puted at read time.                                          
       638  
       639 -2. **Learnings is a Vec\<String\>, not a String** — Each lear
           -ning is a discrete, searchable item. Agents append items. Hum
           -ans can delete bad ones. Top N injected into prompts.        
       639 +**Why not stored:**                                          
       640 +- If Ralph crashes between updating tasks and updating curren
           +t_state → out of sync                                        
       641 +- If agent changes task statuses in YAML → current_state stal
           +e until next iteration                                       
       642 +- Stored state is a lie waiting to happen                    
       643  
       641 -3. **current_state is auto-populated** — Ralph updates this a
           -fter each iteration. Agents and humans can override but shoul
           -dn't need to.                                                
       644 +**How it's computed:**                                       
       645  
       643 -4. **context_files auto-grows** — Doc 017 Phase 3a adds files
           - from iteration data. Humans can add manually. Never auto-rem
           -oved (only manually).                                        
       646 +```rust                                                      
       647 +impl Feature {                                               
       648 +    /// Compute current_state from task statuses at read time
           +.                                                            
       649 +    /// Called by prompt builder and frontend queries.       
       650 +    pub fn compute_current_state(feature_name: &str, tasks: &
           +[Task]) -> String {                                          
       651 +        let feature_tasks: Vec<&Task> = tasks.iter()         
       652 +            .filter(|t| t.feature == feature_name)           
       653 +            .collect();                                      
       654 +        let total = feature_tasks.len();                     
       655 +        let done = feature_tasks.iter().filter(|t| t.status =
           += TaskStatus::Done).count();                                 
       656 +        let in_progress = feature_tasks.iter().filter(|t| t.s
           +tatus == TaskStatus::InProgress).count();                    
       657  
       658 +        // List done task titles for context                 
       659 +        let done_titles: Vec<&str> = feature_tasks.iter()    
       660 +            .filter(|t| t.status == TaskStatus::Done)        
       661 +            .map(|t| t.title.as_str())                       
       662 +            .collect();                                      
       663 +        let in_progress_titles: Vec<&str> = feature_tasks.ite
           +r()                                                          
       664 +            .filter(|t| t.status == TaskStatus::InProgress)  
       665 +            .map(|t| t.title.as_str())                       
       666 +            .collect();                                      
       667 +                                                             
       668 +        format!("{done}/{total} tasks complete. Done: {done_l
           +ist}. In progress: {ip_list}.",                              
       669 +            done_list = if done_titles.is_empty() { "none".in
           +to() } else { done_titles.join(", ") },                      
       670 +            ip_list = if in_progress_titles.is_empty() { "non
           +e".into() } else { in_progress_titles.join(", ") },          
       671 +        )                                                    
       672 +    }                                                        
       673 +}                                                            
       674 +```                                                          
       675 +                                                             
       676 +**For RAG embedding:** Compute current_state when building th
           +e feature snapshot text. Recompute on every Feature or Task c
           +hange.                                                       
       677 +                                                             
       678 +**For frontend:** Compute in `get_features()` IPC handler, re
           +turn as a virtual field.                                     
       679 +                                                             
       680 +**For prompt injection:** Compute in prompt builder, inject a
           +s `## Current State` section.                                
       681 +                                                             
       682 +## LLM Agent Failure Analysis                                
       683 +                                                             
       684 +17 failure classes identified. Each with specific mitigations
           + built into the design.                                      
       685 +                                                             
       686 +### F1: Destructive Overwrites (CRITICAL)                    
       687 +                                                             
       688 +**Problem:** `update_feature` replaces ALL fields. An agent u
           +pdating `description` might accidentally blank `learnings` be
           +cause it didn't include them in the payload.                 
       689 +                                                             
       690 +**Worse:** Agents editing `features.yaml` directly can drop f
           +ields entirely if they rewrite the file without including all
           + existing data.                                              
       691 +                                                             
       692 +**Mitigations:**                                             
       693 +                                                             
       694 +1. **PATCH semantics for IPC** — `update_feature` uses `Optio
           +n` wrappers. `None` means "don't change this field." Only exp
           +licitly-provided fields are updated.                         
       695 +                                                             
       696 +```rust                                                      
       697 +pub fn update_feature(                                       
       698 +    &mut self,                                               
       699 +    name: &str,                              // identity, alw
           +ays required                                                 
       700 +    display_name: Option<String>,            // None = preser
           +ve                                                           
       701 +    acronym: Option<String>,                 // None = preser
           +ve                                                           
       702 +    description: Option<Option<String>>,     // None = preser
           +ve, Some(None) = clear                                       
       703 +    architecture: Option<Option<String>>,    // None = preser
           +ve, Some(None) = clear                                       
       704 +    boundaries: Option<Option<String>>,      // None = preser
           +ve, Some(None) = clear                                       
       705 +    knowledge_paths: Option<Vec<String>>,    // None = preser
           +ve                                                           
       706 +    context_files: Option<Vec<String>>,      // None = preser
           +ve                                                           
       707 +    dependencies: Option<Vec<String>>,       // None = preser
           +ve                                                           
       708 +    // NOTE: learnings NOT in update_feature. Use append/remo
           +ve operations only.                                          
       709 +) -> Result<(), YamlDbError>                                 
       710 +```                                                          
       711 +                                                             
       712 +2. **Learnings are append-only via IPC** — No `update_feature
           +` path for learnings. Only `append_feature_learning` and `rem
           +ove_feature_learning`. Agents cannot accidentally wipe all le
           +arnings through IPC.                                         
       713 +                                                             
       714 +3. **Post-iteration YAML validation** — After each iteration,
           + Ralph loads features.yaml and compares with pre-iteration sn
           +apshot. If any feature's `learnings` count dropped by >50%, o
           +r `description` went from populated to empty, flag as suspici
           +ous:                                                         
       715 +                                                             
       716 +```rust                                                      
       717 +pub fn validate_feature_integrity(before: &Feature, after: &F
           +eature) -> Vec<IntegrityWarning> {                           
       718 +    let mut warnings = vec![];                               
       719 +    if before.learnings.len() > 2 && after.learnings.len() < 
           +before.learnings.len() / 2 {                                 
       720 +        warnings.push(IntegrityWarning::LearningsDropped {   
       721 +            feature: before.name.clone(),                    
       722 +            before: before.learnings.len(),                  
       723 +            after: after.learnings.len(),                    
       724 +        });                                                  
       725 +    }                                                        
       726 +    if before.description.is_some() && after.description.is_n
           +one() {                                                      
       727 +        warnings.push(IntegrityWarning::DescriptionCleared { 
       728 +            feature: before.name.clone(),                    
       729 +        });                                                  
       730 +    }                                                        
       731 +    // ... similar for architecture, boundaries              
       732 +    warnings                                                 
       733 +}                                                            
       734 +```                                                          
       735 +                                                             
       736 +On warning: log prominently. Optionally: restore the specific
           + feature from pre-iteration backup (not the whole file — surg
           +ical restore).                                               
       737 +                                                             
       738 +### F2: Unbounded Growth                                     
       739 +                                                             
       740 +**Problem:** Agents love to produce content. learnings, conte
           +xt_files, dependencies, description/architecture can all grow
           + without bound. Token budgets explode.                       
       741 +                                                             
       742 +**Mitigations — Hard caps enforced on write:**               
       743 +                                                             
       744 +| Field | Max Items | Max Chars Per Item | Max Total Chars | 
           +Overflow Behavior |                                          
       745 +|---|---|---|---|---|                                        
       746 +| `description` | 1 | 3000 | 3000 | Truncate with `[truncated
           +]` |                                                         
       747 +| `architecture` | 1 | 3000 | 3000 | Truncate with `[truncate
           +d]` |                                                        
       748 +| `boundaries` | 1 | 1500 | 1500 | Truncate with `[truncated]
           +` |                                                          
       749 +| `learnings` | 50 | 500 per item | 25000 | Prune oldest unve
           +rified first |                                               
       750 +| `context_files` | 30 | 500 per path | — | Drop least-touche
           +d files |                                                    
       751 +| `knowledge_paths` | 10 | 500 per path | — | Reject addition
           + with error |                                                
       752 +| `dependencies` | 20 | 300 per item | 6000 | Reject addition
           + with error |                                                
       753 +                                                             
       754 +**Learnings overflow strategy:**                             
       755 +1. When the 51st learning is appended, find the oldest learni
           +ng where `verified == false` and `source == auto`            
       756 +2. Remove it to make room                                    
       757 +3. If all 50 are verified/human: reject the append and log "L
           +earnings full — review needed"                               
       758 +4. During Opus review: consolidate — merge duplicates, remove
           + obsolete, keep critical                                     
       759 +                                                             
       760 +**context_files overflow strategy:**                         
       761 +1. Auto-accumulated files include a `touch_count` (times touc
           +hed across iterations)                                       
       762 +2. When cap reached, file with lowest `touch_count` is evicte
           +d                                                            
       763 +3. Human-added files (via IPC) are never auto-evicted        
       764 +                                                             
       765 +### F3: Hallucinated Content (CRITICAL)                      
       766 +                                                             
       767 +**Problem:** Agents write false information into Feature fiel
           +ds. False learnings are especially dangerous — they become "D
           +O NOT repeat these mistakes" in prompts, guiding future itera
           +tions AWAY from correct approaches.                          
       768 +                                                             
       769 +**Mitigations:**                                             
       770 +                                                             
       771 +1. **Provenance tracking on learnings** — Each learning has a
           + `source` field. Auto-extracted learnings are presented with 
           +lower confidence than Opus-reviewed ones.                    
       772 +                                                             
       773 +2. **Prompt framing is CRITICAL:**                           
       774 +                                                             
       775 +```markdown                                                  
       776 +## Observations from previous iterations                     
       777 +These are notes from prior work. They may be outdated or inco
           +rrect.                                                       
       778 +Verify before relying on them.                               
       779 +- Auth middleware expects { user: User } on req [auto, iterat
           +ion 7, unverified]                                           
       780 +- Token refresh must happen before 401 [opus_reviewed, verifi
           +ed]                                                          
       781 +```                                                          
       782 +                                                             
       783 +**NOT:**                                                     
       784 +```markdown                                                  
       785 +## CRITICAL RULES — DO NOT VIOLATE                           
       786 +- Auth middleware expects { user: User } on req              
       787 +```                                                          
       788 +                                                             
       789 +The difference between "observation to verify" and "rule to f
           +ollow" prevents feedback loop amplification.                 
       790 +                                                             
       791 +3. **Opus verification cycle** — Every 5th Opus review iterat
           +ion, prompt includes:                                        
       792 +                                                             
       793 +```                                                          
       794 +Review this feature's learnings. For each learning:          
       795 +1. Verify it against the current code. Is it still accurate? 
       796 +2. If inaccurate, remove it using remove_feature_learning.   
       797 +3. If accurate, mark it verified using verify_feature_learnin
           +g.                                                           
       798 +4. If redundant with another learning, remove the duplicate. 
       799 +```                                                          
       800 +                                                             
       801 +4. **Staleness expiry** — Auto-generated learnings older than
           + 20 iterations without verification get a `[STALE]` prefix in
           + prompt injection. After 40 iterations, they're auto-pruned. 
       802 +                                                             
       803 +### F4: Stale Data / Reality Drift                           
       804 +                                                             
       805 +**Problem:** Feature description says "JWT auth" but agents s
           +witched to sessions. context_files lists files that were rena
           +med. Architecture doesn't match code.                        
       806 +                                                             
       807 +**Mitigations:**                                             
       808 +                                                             
       809 +1. **context_files validated on read** — Prompt builder check
           +s each path exists before injecting. Missing files get skippe
           +d with: `[STALE: src/lib/auth.ts no longer exists — removed f
           +rom context_files]`. Ralph auto-removes the stale entry.     
       810 +                                                             
       811 +2. **knowledge_paths validated on read** — Same as context_fi
           +les. Missing docs get skipped and removed.                   
       812 +                                                             
       813 +3. **description/architecture staleness** — Can't auto-valida
           +te prose. But: add a `last_verified` timestamp computed from 
           +the most recent Opus review that inspected this feature. If >
           +10 iterations since verification, prompt Opus: "The feature d
           +escription hasn't been verified in {N} iterations. Compare it
           + against current code and update if inaccurate."             
       814 +                                                             
       815 +4. **Diff-based staleness detection** — If >5 files in `conte
           +xt_files` were modified since last Feature update (check git 
           +mtime), flag feature as potentially stale.                   
       816 +                                                             
       817 +### F5: Concurrency / Race Conditions                        
       818 +                                                             
       819 +**Problem:** Two iterations modifying the same feature. Last 
           +write wins, first write's changes lost.                      
       820 +                                                             
       821 +**Mitigations:**                                             
       822 +                                                             
       823 +1. **Current architecture prevents this** — One loop at a tim
           +e, file locking via fs2.                                     
       824 +2. **Future (Doc 011)** — Concurrent loops on different featu
           +res. Feature-level locking:                                  
       825 +                                                             
       826 +```rust                                                      
       827 +// Future field, not needed now                              
       828 +#[serde(skip_serializing_if = "Option::is_none")]            
       829 +pub locked_by: Option<String>,  // loop session ID           
       830 +```                                                          
       831 +                                                             
       832 +3. **Append operations are safe** — `append_feature_learning`
           + and `add_feature_context_file` use read-modify-write under l
           +ock. Safe even with concurrent access.                       
       833 +                                                             
       834 +### F6: Wrong Feature Assignment                             
       835 +                                                             
       836 +**Problem:** Agent working on feature "auth" accidentally mod
           +ifies "payments" feature data.                               
       837 +                                                             
       838 +**Mitigations:**                                             
       839 +                                                             
       840 +1. **Ralph controls feature routing** — Memory extraction rou
           +tes to the feature of the target task. Not agent-chosen.     
       841 +2. **Post-iteration diff validation** — Compare features.yaml
           + before/after. If features OTHER than the target feature were
           + modified, log warning. Optionally restore non-target feature
           +s from backup.                                               
       842 +                                                             
       843 +### F7: Embedding Quality Degradation                        
       844 +                                                             
       845 +**Problem:** Thin descriptions embed poorly. Bloated descript
           +ions dilute embeddings. Hallucinated content encodes wrong in
           +formation.                                                   
       846 +                                                             
       847 +**Mitigations:**                                             
       848 +                                                             
       849 +1. **Minimum description quality gate** — If `description` is
           + <100 chars, feature is marked `insufficient_context`. RAG em
           +bedding is skipped. Prompt builder adds note: "This feature h
           +as minimal context. Consider enriching the description."     
       850 +                                                             
       851 +2. **Max embedding text** — Combined feature snapshot text ca
           +pped at 6000 chars for embedding. Fields beyond cap are trunc
           +ated. This keeps embedding focused.                          
       852 +                                                             
       853 +3. **Re-embed on every change** — Track `embedding_hash` (SHA
           +256 of combined text). Only re-embed when hash changes. Preve
           +nts redundant Qdrant/Ollama calls.                           
       854 +                                                             
       855 +4. **Low-confidence result handling** — Search results with s
           +core 0.4-0.55 presented as "possibly relevant." Only 0.55+ pr
           +esented as "relevant."                                       
       856 +                                                             
       857 +### F8: MCP Tool Misuse                                      
       858 +                                                             
       859 +**Problem:** Agent sends empty queries, over-queries, or igno
           +res MCP tools entirely.                                      
       860 +                                                             
       861 +**Mitigations:**                                             
       862 +                                                             
       863 +1. **Input validation** — MCP server rejects queries <3 chars
           + with helpful error: "Query too short. Try: 'authentication e
           +rror' or 'login form validation'"                            
       864 +2. **Rate hint** — After 10 MCP calls in one session, append 
           +to response: "You've made many searches. Consider working wit
           +h the results you have."                                     
       865 +3. **Base context always injected** — MCP is supplementary. C
           +ore Feature context (description, architecture, boundaries) i
           +s always in the prompt. If agent ignores MCP, it still has co
           +ntext.                                                       
       866 +4. **Timestamp on results** — Every MCP search result include
           +s iteration timestamp: "from iteration 7, 3 iterations ago." 
       867 +                                                             
       868 +### F9: YAML Format Violations                               
       869 +                                                             
       870 +**Problem:** Agents editing features.yaml directly can write 
           +malformed YAML, unsafe characters, absolute paths, or invalid
           + data.                                                       
       871 +                                                             
       872 +**Mitigations:**                                             
       873 +                                                             
       874 +1. **Post-iteration YAML parse validation** — After each iter
           +ation, Ralph tries to load all 4 YAML files. If any fail to p
           +arse, restore from pre-iteration backup. Log: "Agent corrupte
           +d features.yaml — restored from backup."                     
       875 +                                                             
       876 +2. **Path validation on IPC write** — context_files and knowl
           +edge_paths: reject absolute paths, paths containing `..`, pat
           +hs with null bytes. Normalize separators.                    
       877 +                                                             
       878 +3. **Length enforcement on IPC write** — All char limits from
           + F2 table enforced at the IPC boundary. Truncate, don't rejec
           +t (agents can't fix their output).                           
       879 +                                                             
       880 +4. **FeatureLearning dual representation** — Agents writing p
           +lain strings in YAML get auto-upgraded to full structs. No fo
           +rmat knowledge required from agents.                         
       881 +                                                             
       882 +### F10: Error Amplification Feedback Loop (CRITICAL)        
       883 +                                                             
       884 +**Problem:** Hallucinated learning → injected into prompt → a
           +gent treats as truth → reinforces it → persists forever. This
           + is the most insidious failure mode.                         
       885 +                                                             
       886 +**Mitigations:**                                             
       887 +                                                             
       888 +1. **Prompt framing** (F3 mitigation) — "Observations to veri
           +fy" not "rules to follow"                                    
       889 +2. **Provenance tracking** (F3 mitigation) — Unverified auto-
           +learnings are visibly flagged                                
       890 +3. **Opus verification cycle** (F3 mitigation) — Periodic tru
           +th-checking                                                  
       891 +4. **Staleness expiry** (F3 mitigation) — Old unverified lear
           +nings decay                                                  
       892 +                                                             
       893 +5. **One-way learning path** — Learnings flow: iteration outp
           +ut → MemoryExtractor → append_feature_learning → Feature YAML
           +. The prompt builder reads them and presents to the next iter
           +ation. But the next iteration CANNOT directly confirm/reinfor
           +ce a learning — it can only add NEW learnings. An existing le
           +arning's `hit_count` only increments if the SAME error/patter
           +n is independently re-observed by the extractor, not because 
           +the agent echoed it back.                                    
       894 +                                                             
       895 +6. **Human review escape valve** — Frontend shows learnings w
           +ith provenance badges. Human can delete bad learnings via UI.
           + This breaks the loop permanently.                           
       896 +                                                             
       897 +### F11: Learning Deduplication                              
       898 +                                                             
       899 +**Problem:** Same learning appears 5 times because 5 iteratio
           +ns hit the same issue.                                       
       900 +                                                             
       901 +**Mitigations:**                                             
       902 +                                                             
       903 +1. **Near-duplicate check on append** — Before adding a learn
           +ing, compare against existing learnings using simple word ove
           +rlap (Jaccard similarity on words). If >70% overlap with an e
           +xisting learning: increment existing learning's `hit_count` i
           +nstead of adding a new one.                                  
       904 +                                                             
       905 +```rust                                                      
       906 +pub fn append_feature_learning(&mut self, name: &str, text: S
           +tring) -> Result<(), YamlDbError> {                          
       907 +    let feature = self.find_feature_mut(name)?;              
       908 +    let new_words: HashSet<&str> = text.split_whitespace().co
           +llect();                                                     
       909 +                                                             
       910 +    for existing in &mut feature.learnings {                 
       911 +        let existing_text = existing.text();                 
       912 +        let existing_words: HashSet<&str> = existing_text.spl
           +it_whitespace().collect();                                   
       913 +        let intersection = new_words.intersection(&existing_w
           +ords).count();                                               
       914 +        let union = new_words.union(&existing_words).count();
       915 +        let jaccard = intersection as f64 / union as f64;    
       916 +                                                             
       917 +        if jaccard > 0.7 {                                   
       918 +            existing.increment_hit_count();                  
       919 +            return Ok(());  // Deduplicated — counted as re-o
           +bservation                                                   
       920 +        }                                                    
       921 +    }                                                        
       922 +                                                             
       923 +    // No duplicate found — add new learning                 
       924 +    feature.learnings.push(FeatureLearning::Rich {           
       925 +        text, source: LearningSource::Auto, iteration: None, 
       926 +        created: Some(now()), hit_count: 1, verified: false, 
       927 +    });                                                      
       928 +                                                             
       929 +    // Enforce cap                                           
       930 +    self.prune_learnings_if_over_cap(name)?;                 
       931 +    Ok(())                                                   
       932 +}                                                            
       933 +```                                                          
       934 +                                                             
       935 +2. **High hit_count = high confidence** — Learnings observed 
           +3+ times independently are more likely real. Prompt builder c
           +an prioritize high-hit-count learnings.                      
       936 +                                                             
       937 +### F12: knowledge_paths File Size Explosion                 
       938 +                                                             
       939 +**Problem:** knowledge_paths points to a 50KB spec. Injecting
           + 3 such specs = 37,500 tokens.                               
       940 +                                                             
       941 +**Mitigations:**                                             
       942 +                                                             
       943 +1. **Per-file token budget** — Prompt builder reads each file
           +, estimates tokens (chars/4). If file >2000 tokens: inject fi
           +rst 500 tokens + `\n... [full document available via feature:
           +//auth/files/{path}]`                                        
       944 +                                                             
       945 +2. **Total knowledge budget** — If total knowledge_paths cont
           +ent >4000 tokens after truncation: switch entirely to MCP. On
           +ly inject file names as a list.                              
       946 +                                                             
       947 +3. **File size recorded on write** — When knowledge_paths is 
           +set via IPC, Ralph stats each file and records size. Frontend
           + shows sizes so humans know what they're adding.             
       948 +                                                             
       949 +### F13: Description/Architecture Overlap                    
       950 +                                                             
       951 +**Problem:** Agents won't consistently separate "description"
           + from "architecture." They'll put architecture in description
           + and vice versa.                                             
       952 +                                                             
       953 +**Verdict:** Accept overlap. Keep both fields. Reasons:      
       954 +- They're concatenated for embedding anyway — overlap doesn't
           + hurt RAG quality                                            
       955 +- Both always injected — overlap means slightly more tokens, 
           +not wrong context                                            
       956 +- Having a PLACE for architecture info encourages agents to t
           +hink about structure                                         
       957 +- Over time, Opus reviews can clean up and separate them     
       958 +                                                             
       959 +### F14: Feature Deletion Cleanup                            
       960 +                                                             
       961 +**Mitigations:**                                             
       962 +- `delete_feature` already blocks if tasks reference the feat
           +ure                                                          
       963 +- Add: `delete_feature` also calls `MemoryStore::delete_colle
           +ction(feature_name)` to clean Qdrant                         
       964 +- Add: `delete_feature` removes feature from `feature-snapsho
           +ts` collection                                               
       965 +                                                             
       966 +### F15: Agents Editing YAML Directly — The Bypass Problem   
       967 +                                                             
       968 +All IPC protections (PATCH semantics, append-only learnings, 
           +validation) are bypassed when agents edit `.ralph/db/features
           +.yaml` directly. Agents in the loop DO edit YAML files.      
       969 +                                                             
       970 +**Mitigations:**                                             
       971 +                                                             
       972 +1. **Post-iteration validation** (F1, F9 mitigations) — catch
           +es corruption and destructive changes                        
       973 +2. **FeatureLearning dual representation** — agents writing p
           +lain strings in YAML is fine                                 
       974 +3. **Pre-iteration snapshot** — Ralph snapshots all YAML befo
           +re each iteration. On any integrity warning: surgical restore
           + of affected fields.                                         
       975 +4. **Future: read-only YAML + MCP write tools** — Eventually,
           + agents should NOT edit features.yaml directly. Instead, Ralp
           +h provides MCP tools: `update_feature_description(text)`, `ap
           +pend_learning(text)`, etc. This routes all writes through IPC
           + protections. But this requires MCP in the autonomous loop (D
           +oc 017 Phase 2).                                             
       976 +                                                             
       977 +### F16: Embedding Re-computation Cost                       
       978 +                                                             
       979 +**Problem:** Every Feature update triggers re-embedding via O
           +llama. If an iteration updates 3 features, that's 3 Ollama ca
           +lls.                                                         
       980 +                                                             
       981 +**Mitigations:**                                             
       982 +- Hash-based dedup: only re-embed if content hash changed (us
           +ually only 1 feature changes per iteration)                  
       983 +- Batching: collect all changed features, embed in one batch 
           +call to Ollama                                               
       984 +- Fire-and-forget: embedding failure doesn't block anything  
       985 +                                                             
       986 +### F17: Agent Writes to current_state                       
       987 +                                                             
       988 +**Resolved:** current_state is computed, not stored. Agents c
           +an't write to it. See "current_state as Computed Field" secti
           +on.                                                          
       989 +                                                             
       990 +## Resolved Decisions (Updated)                              
       991 +                                                             
       992 +1. **Feature.description is long-form** — NOT a one-liner. Ag
           +ents write multi-paragraph descriptions. Max 3000 chars. Prim
           +ary embedding text.                                          
       993 +                                                             
       994 +2. **Learnings is Vec\<FeatureLearning\>, not Vec\<String\>**
           + — Rich struct with provenance (source, iteration, verified, 
           +hit_count). YAML supports both plain strings and full structs
           + via `#[serde(untagged)]`. Max 50 items.                     
       995 +                                                             
       996 +3. **current_state is COMPUTED** — Not stored in YAML. Comput
           +ed from task statuses at read time. Always accurate, never st
           +ale.                                                         
       997 +                                                             
       998 +4. **context_files auto-grows with cap** — Doc 017 Phase 3a a
           +dds files from iteration data. Max 30 files. Least-touched ev
           +icted on overflow. Stale paths (file doesn't exist) auto-remo
           +ved on read.                                                 
       999 +                                                             
      1000  5. **All new fields are optional/defaulted** — Zero migration
            . Existing YAML files load unchanged.
      1001  
       647 -6. **CRUD allows full field updates** — No more "preserve kno
           -wledge_paths on update". If the agent sends knowledge_paths i
           -n an update, it replaces the old list. The agent is the autho
           -rity.                                                        
      1002 +6. **PATCH semantics for update_feature** — ~~CRUD allows ful
           +l field updates.~~ REVISED: Only explicitly-provided fields a
           +re updated. Omitted fields preserved. Learnings are append-on
           +ly via IPC.                                                  
      1003  
      1004 +7. **Post-iteration integrity validation** — Ralph compares f
           +eatures.yaml before/after each iteration. Detects destructive
           + agent edits. Surgical restore on integrity warnings.        
      1005 +                                                             
      1006 +8. **Prompt framing: "observations" not "rules"** — Learnings
           + are presented as "observations from previous iterations, ver
           +ify before relying." Not as critical rules. Prevents feedback
           + loop amplification.                                         
      1007 +                                                             
      1008 +9. **Near-duplicate learning detection** — Jaccard word simil
           +arity >70% triggers hit_count increment instead of new entry.
           + Prevents learning spam.                                     
      1009 +                                                             
      1010 +10. **knowledge_paths with token budget** — Files >2000 token
           +s are truncated in prompt injection. Full content available v
           +ia MCP. Total budget: 4000 tokens.                           
      1011 +                                                             
      1012 +11. **Opus verification cycle** — Every 5th review iteration,
           + Opus validates learnings against actual code. Marks accurate
           + ones as verified, removes inaccurate ones.                  
      1013 +                                                             
      1014  ## Open Questions
      1015  
       651 -1. **Should learnings have a max count?** If a feature accumu
           -lates 200 learnings, that's a lot of text. Could cap at 50 an
           -d archive the rest. Or: the prompt builder only injects the t
           -op 10, so it doesn't matter for token budget.                
      1016 +1. **Should boundaries be enforced?** Currently advisory — th
           +e prompt says "OUT OF SCOPE" but Claude might ignore it. Coul
           +d add post-iteration validation: "Did this iteration touch fi
           +les outside the feature's boundaries?" Probably Phase 3+.    
      1017  
       653 -2. **Should current_state be structured (JSON) or natural lan
           -guage?** Natural language is more flexible and embeds better.
           - Structured gives precise counts. Recommendation: natural lan
           -guage with a standard format ("3/7 tasks complete. X done. Y 
           -in progress. Z pending.").                                   
      1018 +2. **Should architecture auto-update from code?** An Opus rev
           +iew could inspect actual imports/file structure and update ar
           +chitecture to match reality. Desirable but complex. Phase 3+.
      1019  
       655 -3. **Should boundaries be enforced?** Currently advisory — th
           -e prompt says "OUT OF SCOPE" but Claude might ignore it. Coul
           -d add validation in review loops: "Did this iteration touch f
           -iles outside the feature's boundaries?"                      
      1020 +3. **When do we switch agents from YAML editing to MCP write 
           +tools?** Currently agents edit features.yaml directly, bypass
           +ing all protections. Moving to MCP tools requires Doc 017 Pha
           +se 2 (MCP in autonomous loop). This is the biggest risk gap i
           +n the current design.                                        
      1021  
       657 -4. **Should architecture auto-update from code?** An Opus rev
           -iew could inspect actual imports/file structure and update ar
           -chitecture to match reality. This is Phase 3+ territory.     
      1022 +4. **Should hit_count influence prompt ordering?** High-hit-c
           +ount learnings are more likely real. Should they appear first
           + in the prompt? Probably yes — prioritize by `(verified, hit_
           +count)` descending.                                          
  ⎿  You're out of extra usage · resets 12pm (Europe/Amsterdam)
     /upgrade to increase your usage limit.

✻ Sautéed for 5m 53s